{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20210204_AutoEncoder_Fraud Detection.ipynb",
      "provenance": [],
      "mount_file_id": "1bsIg9nDAR128qxYlbrAQEYNNnX5Wk3mT",
      "authorship_tag": "ABX9TyM2R8mUFD03XNaAQbiHh47V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc596dc0a52549f9b2c4bac243d81cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5dc58762d31c41c58f4ef6e2744afcfa",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79ca62ee9588400b95d07fbb985929ed"
          }
        },
        "5dc58762d31c41c58f4ef6e2744afcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79ca62ee9588400b95d07fbb985929ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "633b199a0a674e5492b7ed62d8a11546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_4c40f7baad914941bfa9db5ad9914c22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "TextModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Following data types have been inferred automatically, if they are correct press enter to continue or type 'quit' otherwise.",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff733433cd964bf2980eed59a8ee7fa5"
          }
        },
        "4c40f7baad914941bfa9db5ad9914c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff733433cd964bf2980eed59a8ee7fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8f403f33a884b8caab945988e433994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_047ba611ab2e4b1b97a0e6e9ef8ebcca",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 79,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 79,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3d3023c2d514a9fa2fb5ffd01214fa5"
          }
        },
        "047ba611ab2e4b1b97a0e6e9ef8ebcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3d3023c2d514a9fa2fb5ffd01214fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d82bfb9923241df8d11ac134a45ed88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1fcc3dbbaf6d45139043e91695f65b38",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_692b3f46b3bc4184a1113ff0142216f3"
          }
        },
        "1fcc3dbbaf6d45139043e91695f65b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "692b3f46b3bc4184a1113ff0142216f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f39c80ebcb64bb6ab6782cb467dad2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34f8b9d6e326450fb575c3beebd72475",
            "_dom_classes": [],
            "description": "Processing: ",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 7,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ec615d3dde8448692f9700b8e38388d"
          }
        },
        "34f8b9d6e326450fb575c3beebd72475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ec615d3dde8448692f9700b8e38388d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerenalli/DATA_MINING/blob/main/20210204_AutoEncoder_Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2rZHO5DxZw",
        "outputId": "99dd176d-5075-44f2-90e2-5082a8adad8b"
      },
      "source": [
        "!pip install pycaret tpot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/7b/70e41d8aa900ed47e0e2ac6a8f5cbaf9e359efdf8ae10bf89502c14ce3ed/pycaret-2.2.3-py3-none-any.whl (249kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 6.1MB/s \n",
            "\u001b[?25hCollecting tpot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/55/a7185198f554ea19758e5ac4641f100c94cba4585e738e2e48e3c40a0b7f/TPOT-0.11.7-py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.4MB/s \n",
            "\u001b[?25hCollecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Collecting pyod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/26/ae4f4143643d2d87fe4bbc356064dd95eed95227b879ba3ee6c4e4ee81ca/pyod-0.8.6.tar.gz (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.1.5)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/bb/57fd86c319a43666fe447bb1bc5af66fb0eb89dc4efc305a7544d50f52d6/yellowbrick-1.2.1-py3-none-any.whl (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.19.5)\n",
            "Collecting imbalanced-learn>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/81/8db4d87b03b998fda7c6f835d807c9ae4e3b141f978597b8d7f31600be15/imbalanced_learn-0.7.0-py3-none-any.whl (167kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting pandas-profiling>=2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/8e/645ad7f304dd8d6d7181d22d4bd3d6356331c80c2944a25be3ebe617ec38/pandas_profiling-2.10.0-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 15.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from pycaret) (2.2.4)\n",
            "Collecting catboost>=0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n",
            "\u001b[K     |████████████████████████████████| 65.8MB 69kB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pycaret) (1.0.0)\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.14.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from pycaret) (7.6.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.5)\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/55/d8ec1ae1f7e1e202a8a4184c6852a3ee993b202b0459672c699d0ac18fc8/kmodes-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.6/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting mlflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/4d/a6a4460e214842377dbc43d3e83bf976d564f7976822a9351adde60af44b/mlflow-1.13.1-py3-none-any.whl (14.1MB)\n",
            "\u001b[K     |████████████████████████████████| 14.2MB 55.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from pycaret) (0.11.1)\n",
            "Collecting lightgbm>=2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/cd/2b7783e8c250f8191b72e9a0010e0429a799d3305c27764d7bf113dfd078/lightgbm-3.1.1-py2.py3-none-manylinux1_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 50.9MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8MB 39.5MB/s \n",
            "\u001b[?25hCollecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 47.2MB/s \n",
            "\u001b[?25hCollecting xgboost>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/57/bf5026701c384decd2b995eb39d86587a103ba4eb26f8a9b1811db0896d3/xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5MB)\n",
            "\u001b[K     |████████████████████████████████| 157.5MB 82kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pycaret) (3.2.2)\n",
            "Collecting deap>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/eb/2bd0a32e3ce757fb26264765abbaedd6d4d3640d90219a513aeabd08ee2b/deap-1.3.1-cp36-cp36m-manylinux2010_x86_64.whl (157kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 48.1MB/s \n",
            "\u001b[?25hCollecting update-checker>=0.16\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/ba/8dd7fa5f0b1c6a8ac62f8f57f7e794160c1f86f31c6d0fb00f582372a3e4/update_checker-0.18.0-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.41.1)\n",
            "Collecting stopit>=1.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/35/58/e8bb0b0fb05baf07bbac1450c447d753da65f9701f551dca79823ce15d50/stopit-1.1.2.tar.gz\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.4.1)\n",
            "Collecting combo\n",
            "  Downloading https://files.pythonhosted.org/packages/12/ae/66029dcaa88ccca77f454dbb29c1178c751ec24fc771ed475a992b49a02d/combo-0.1.2.tar.gz\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Collecting suod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/8a/255ed2c959abab7c712b10fe710e454d5a8e3461c6ae60e426349a8eb6a5/suod-0.0.6.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.6/dist-packages (from umap-learn->pycaret) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from yellowbrick>=1.0.1->pycaret) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (53.0.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Collecting requests>=2.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.2)\n",
            "Collecting confuse>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6d/55/b4726d81e5d6509fa3441f770f8a9524612627dc1b2a7d6209d1d20083fe/confuse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (20.3.0)\n",
            "Collecting visions[type_image_path]==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/30/b1e70bc55962239c4c3c9660e892be2d8247a882135a3035c10ff7f02cde/visions-0.6.0-py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[?25hCollecting phik>=0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/27/d4197ed93c26d9eeedb7c73c0f24462a65c617807c3140e012950c35ccf9/phik-0.11.0.tar.gz (594kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 49.3MB/s \n",
            "\u001b[?25hCollecting tangled-up-in-unicode>=0.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/e2/e588ab9298d4989ce7fdb2b97d18aac878d99dbdc379a4476a09d9271b68/tangled_up_in_unicode-0.0.6-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 32.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.8.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (3.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->pycaret) (0.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost>=0.23.2->pycaret) (0.10.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->pycaret) (4.1.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->pycaret) (7.0.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (1.0.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.3.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->pycaret) (5.1.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.22)\n",
            "Collecting gitpython>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/cb/ec98155c501b68dcb11314c7992cd3df6dce193fd763084338a117967d53/GitPython-3.1.12-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.13)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/88/ae1f78cf582b707c605c77df49b4c8786a4465edc51adb25d2f98ef4c4de/databricks-cli-0.14.1.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hCollecting querystring-parser\n",
            "  Downloading https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (3.12.4)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (1.1.2)\n",
            "Collecting alembic<=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/e9/359dbb77c35c419df0aedeb1d53e71e7e3f438ff64a8fdb048c907404de3/alembic-1.4.1.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 37.0MB/s \n",
            "\u001b[?25hCollecting gunicorn; platform_system != \"Windows\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/ca/926f7cd3a2014b16870086b2d0fdc84a9e49473c68a8dff8b57f7c156f43/gunicorn-20.0.4-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hCollecting azure-storage-blob>=12.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/00/6772472a99cd0a5e74e4e90f87947fa041b37981a3ff93d883cbc450518d/azure_storage_blob-12.7.1-py2.py3-none-any.whl (339kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/d5/8a046d683c2cc084b6a502812827ede69b1064f95d93f94b83f809b21723/prometheus_flask_exporter-0.18.1.tar.gz\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Collecting docker>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/a5/eec74d8d1016e6c2042ba31ca6fba3bba520e27d8a061e82bccd36bd64ef/docker-4.4.1-py2.py3-none-any.whl (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from lightgbm>=2.3.1->pycaret) (0.36.2)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (2.7.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/66/89/479de0afbbfb98d1c4b887936808764627300208bb771fcd823403645a36/funcy-1.15-py2.py3-none-any.whl\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from suod->pyod->pycaret) (5.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2020.12.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.11.1->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.6/dist-packages (from visions[type_image_path]==0.6.0->pandas-profiling>=2.8.0->pycaret) (2.5)\n",
            "Collecting imagehash; extra == \"type_image_path\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/9dbb772b5ef73a3069c66bb5bf29b9fb4dd57af0d5790c781c3f559bcca6/ImageHash-4.2.0-py2.py3-none-any.whl (295kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.7.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.7)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/db/2d2d88b924aa4674a080aae83b59ea19d593250bfe5ed789947c21736785/Mako-1.1.4.tar.gz (479kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 41.3MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting cryptography>=2.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 37.7MB/s \n",
            "\u001b[?25hCollecting azure-core<2.0.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/9e/6bb67fe85f6a89d71f50c86a0da778a5064f749a485ed9ba498067034227/azure_core-1.10.0-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 36.5MB/s \n",
            "\u001b[?25hCollecting msrest>=0.6.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cc/6c96bfb3d3cf4c3bdedfa6b46503223f4c2a4fa388377697e0f8082a4fed/msrest-0.6.21-py2.py3-none-any.whl (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: prometheus_client in /usr/local/lib/python3.6/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.9.0)\n",
            "Collecting websocket-client>=0.32.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (8.6.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis->pycaret) (0.7.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.6/dist-packages (from imagehash; extra == \"type_image_path\"->visions[type_image_path]==0.6.0->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->pycaret) (3.4.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.0.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.9.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.5.0)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/1e/6130925131f639b2acde0f7f18b73e33ce082ff2d90783c436b52040af5a/smmap-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow->pycaret) (1.14.4)\n",
            "Collecting isodate>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow->pycaret) (1.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.4.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.2.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.6.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.0.0->mlflow->pycaret) (2.20)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob>=12.0.0->mlflow->pycaret) (3.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (20.8)\n",
            "Building wheels for collected packages: pyod, pyLDAvis, stopit, combo, suod, phik, htmlmin, databricks-cli, alembic, prometheus-flask-exporter, Mako\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.8.6-cp36-none-any.whl size=112146 sha256=66b1cab1f91265f9e4699e820bd7e52897520c920582595929e42622c96380cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/95/81/2c6f52c3d366e7b5ef4770550f8bf0764257c66fbe64deecdb\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97712 sha256=50daf4b2f47f00c0966a51be7c5ddbe9c47d9911d618d107577a2b54a67169d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for stopit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stopit: filename=stopit-1.1.2-cp36-none-any.whl size=11957 sha256=4f62bb0db629dc30d8e19a524cea8f24036782367afbf5e5ca70443e82d3eeb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/85/2b/2580190404636bfc63e8de3dff629c03bb795021e1983a6cc7\n",
            "  Building wheel for combo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for combo: filename=combo-0.1.2-cp36-none-any.whl size=42028 sha256=ad253f1003729a8c18d3482142919f3b6b8517170a38c017b4b3b4aa05287672\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/d9/bf/d1a371a5f0844cd8a53c04c14daa89974c93f429dda9dceb86\n",
            "  Building wheel for suod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suod: filename=suod-0.0.6-cp36-none-any.whl size=2154759 sha256=d4fe4385e93913f8593cf841c2e346b23002603550efba571070dba6782f93be\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/d7/c1/6c778aee7fccfe3c054ea9bab92c5994ae3a0f6bba7078541e\n",
            "  Building wheel for phik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phik: filename=phik-0.11.0-cp36-none-any.whl size=599738 sha256=e4541dde8d6ec2ebb7eb67fbd637d06ba9c241669f7c5fc8a9da9fec7af621ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/54/11/aba77f21075918de02f7964eabfe8c10d5542df9e6ad10b225\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27085 sha256=a43cdacb7940a338eafa6f2951cb9b80746fa215fe6f4ec49b1ff0907b0d7372\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.1-cp36-none-any.whl size=100579 sha256=7f4e0b516c159de4d1c04e36ccaf1555bc1d882fa5cdc9beee51ef8057f859b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/91/ac/5d417ee5ccbb76c8cca096cf4cfb9ed9d49d889d1d1ca0fc39\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=11eaaca076e12d5a54d00d130a35e13882a833f87ea1709962685781ef1d1335\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/07/f7/12f7370ca47a66030c2edeedcc23dec26ea0ac22dcb4c4a0f3\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.1-cp36-none-any.whl size=17159 sha256=edafd747e5278af7fea89d07f8d2419ac3a0560f024e4b5ca9011da42a7bbb88\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/1f/b8/66bd9bc3a9d6c6987ff6c4dfeb6f1fe97b5a0e5ed5849c0437\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=676312ec7e26272e019bb3d2265100adea9094baab1e468a84631e5ddf07456d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/10/d3/aeb26e20d19045e2a68e5d3cbb57432e11b5d9c92c99f98d47\n",
            "Successfully built pyod pyLDAvis stopit combo suod phik htmlmin databricks-cli alembic prometheus-flask-exporter Mako\n",
            "\u001b[31mERROR: pandas-profiling 2.10.0 has requirement tqdm>=4.48.2, but you'll have tqdm 4.41.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: threadpoolctl, scikit-learn, scikit-plot, combo, suod, pyod, yellowbrick, imbalanced-learn, requests, confuse, tangled-up-in-unicode, imagehash, visions, phik, htmlmin, pandas-profiling, catboost, kmodes, smmap, gitdb, gitpython, databricks-cli, querystring-parser, Mako, python-editor, alembic, gunicorn, cryptography, azure-core, isodate, msrest, azure-storage-blob, prometheus-flask-exporter, websocket-client, docker, mlflow, lightgbm, funcy, pyLDAvis, xgboost, pycaret, deap, update-checker, stopit, tpot\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed Mako-1.1.4 alembic-1.4.1 azure-core-1.10.0 azure-storage-blob-12.7.1 catboost-0.24.4 combo-0.1.2 confuse-1.4.0 cryptography-3.3.1 databricks-cli-0.14.1 deap-1.3.1 docker-4.4.1 funcy-1.15 gitdb-4.0.5 gitpython-3.1.12 gunicorn-20.0.4 htmlmin-0.1.12 imagehash-4.2.0 imbalanced-learn-0.7.0 isodate-0.6.0 kmodes-0.10.2 lightgbm-3.1.1 mlflow-1.13.1 msrest-0.6.21 pandas-profiling-2.10.0 phik-0.11.0 prometheus-flask-exporter-0.18.1 pyLDAvis-2.1.2 pycaret-2.2.3 pyod-0.8.6 python-editor-1.0.4 querystring-parser-1.2.4 requests-2.25.1 scikit-learn-0.23.2 scikit-plot-0.3.7 smmap-3.0.5 stopit-1.1.2 suod-0.0.6 tangled-up-in-unicode-0.0.6 threadpoolctl-2.1.0 tpot-0.11.7 update-checker-0.18.0 visions-0.6.0 websocket-client-0.57.0 xgboost-1.3.3 yellowbrick-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP5dXZh_Dttw",
        "outputId": "a2070717-4a01-410b-8a08-6ab52fcf4936"
      },
      "source": [
        "import os \r\n",
        "import pandas as pd \r\n",
        "import numpy as np \r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import seaborn as sb \r\n",
        "from pycaret.datasets import get_data\r\n",
        "from tpot import TPOTClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from pycaret.classification import *\r\n",
        "from sklearn.metrics import classification_report, accuracy_score,f1_score \r\n",
        "from sklearn.metrics import precision_score, recall_score,confusion_matrix \r\n",
        "from sklearn.ensemble import RandomForestClassifier \r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "print(os.listdir('/content/drive/MyDrive/Classification/'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['creditcard.csv', 'v_data', 'Videos', 'mo_data', '.ipynb_checkpoints', 'heart_failure_clinical_records_dataset.csv', 'diabetes.csv', 'dia.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGulvMeTDF8s",
        "outputId": "600f9af3-920a-4f43-c62b-441fba3e3cde"
      },
      "source": [
        "# train autoencoder for regression with no compression in the bottleneck layer\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import ReLU\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from matplotlib import pyplot\r\n",
        "# define dataset\r\n",
        "# getting data \r\n",
        "data=pd.read_csv('/content/drive/MyDrive/Classification/creditcard.csv')\r\n",
        "data.head()\r\n",
        "# splitting data into  X features  and  y target \r\n",
        "X = data.drop(['Class'], axis = 1) \r\n",
        "y = data[\"Class\"] \r\n",
        "print('X: Features || y:Class Labels: \\n')\r\n",
        "print(X.shape,y.shape) \r\n",
        "# Converting to arrays   \r\n",
        "X = X.values \r\n",
        "y = y.values \r\n",
        "# Split the data into training set and testing set \r\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.2, random_state = 42) \r\n",
        "print('After Splitting : \\n')\r\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: Features || y:Class Labels: \n",
            "\n",
            "(284807, 30) (284807,)\n",
            "After Splitting : \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((227845, 30), (56962, 30), (227845,), (56962,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mEWcSG5cEwYC",
        "outputId": "df008f9d-ecad-433a-d888-6141e5132cd0"
      },
      "source": [
        "# number of input columns\r\n",
        "n_inputs = X.shape[1]\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# define encoder\r\n",
        "visible = Input(shape=(n_inputs,))\r\n",
        "e = Dense(n_inputs*2)(visible)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = ReLU()(e)\r\n",
        "# define bottleneck\r\n",
        "n_bottleneck = n_inputs\r\n",
        "bottleneck = Dense(n_bottleneck)(e)\r\n",
        "# define decoder\r\n",
        "d = Dense(n_inputs*2)(bottleneck)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = ReLU()(d)\r\n",
        "# output layer\r\n",
        "output = Dense(n_inputs, activation='linear')(d)\r\n",
        "# define autoencoder model\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "# compile autoencoder model\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=400, batch_size=16, verbose=2, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "14241/14241 - 22s - loss: 0.0031 - val_loss: 0.0059\n",
            "Epoch 2/400\n",
            "14241/14241 - 21s - loss: 4.3415e-04 - val_loss: 5.3360e-04\n",
            "Epoch 3/400\n",
            "14241/14241 - 20s - loss: 3.8520e-04 - val_loss: 0.0021\n",
            "Epoch 4/400\n",
            "14241/14241 - 20s - loss: 3.4595e-04 - val_loss: 9.6185e-04\n",
            "Epoch 5/400\n",
            "14241/14241 - 20s - loss: 3.2473e-04 - val_loss: 9.7071e-04\n",
            "Epoch 6/400\n",
            "14241/14241 - 20s - loss: 3.1126e-04 - val_loss: 0.0012\n",
            "Epoch 7/400\n",
            "14241/14241 - 21s - loss: 2.9721e-04 - val_loss: 0.0091\n",
            "Epoch 8/400\n",
            "14241/14241 - 20s - loss: 2.8599e-04 - val_loss: 2.8788e-04\n",
            "Epoch 9/400\n",
            "14241/14241 - 26s - loss: 2.6607e-04 - val_loss: 0.0014\n",
            "Epoch 10/400\n",
            "14241/14241 - 22s - loss: 2.5183e-04 - val_loss: 0.0022\n",
            "Epoch 11/400\n",
            "14241/14241 - 20s - loss: 2.4048e-04 - val_loss: 0.0036\n",
            "Epoch 12/400\n",
            "14241/14241 - 20s - loss: 2.3137e-04 - val_loss: 0.0033\n",
            "Epoch 13/400\n",
            "14241/14241 - 20s - loss: 2.2241e-04 - val_loss: 0.0017\n",
            "Epoch 14/400\n",
            "14241/14241 - 20s - loss: 2.1398e-04 - val_loss: 4.0665e-04\n",
            "Epoch 15/400\n",
            "14241/14241 - 20s - loss: 2.0850e-04 - val_loss: 3.9974e-04\n",
            "Epoch 16/400\n",
            "14241/14241 - 20s - loss: 2.0425e-04 - val_loss: 0.0012\n",
            "Epoch 17/400\n",
            "14241/14241 - 20s - loss: 1.9756e-04 - val_loss: 0.0013\n",
            "Epoch 18/400\n",
            "14241/14241 - 20s - loss: 1.9165e-04 - val_loss: 0.0022\n",
            "Epoch 19/400\n",
            "14241/14241 - 20s - loss: 1.8728e-04 - val_loss: 0.0048\n",
            "Epoch 20/400\n",
            "14241/14241 - 20s - loss: 1.8059e-04 - val_loss: 0.0026\n",
            "Epoch 21/400\n",
            "14241/14241 - 20s - loss: 1.7768e-04 - val_loss: 4.0706e-04\n",
            "Epoch 22/400\n",
            "14241/14241 - 21s - loss: 1.7621e-04 - val_loss: 0.0016\n",
            "Epoch 23/400\n",
            "14241/14241 - 20s - loss: 1.7245e-04 - val_loss: 0.0013\n",
            "Epoch 24/400\n",
            "14241/14241 - 20s - loss: 1.7204e-04 - val_loss: 3.2853e-04\n",
            "Epoch 25/400\n",
            "14241/14241 - 20s - loss: 1.6795e-04 - val_loss: 0.0019\n",
            "Epoch 26/400\n",
            "14241/14241 - 20s - loss: 1.6850e-04 - val_loss: 3.5579e-04\n",
            "Epoch 27/400\n",
            "14241/14241 - 20s - loss: 1.6727e-04 - val_loss: 0.0168\n",
            "Epoch 28/400\n",
            "14241/14241 - 20s - loss: 1.6663e-04 - val_loss: 0.0012\n",
            "Epoch 29/400\n",
            "14241/14241 - 20s - loss: 1.6521e-04 - val_loss: 8.0165e-04\n",
            "Epoch 30/400\n",
            "14241/14241 - 20s - loss: 1.6451e-04 - val_loss: 0.0047\n",
            "Epoch 31/400\n",
            "14241/14241 - 20s - loss: 1.6438e-04 - val_loss: 2.8749e-04\n",
            "Epoch 32/400\n",
            "14241/14241 - 20s - loss: 1.6280e-04 - val_loss: 7.4212e-04\n",
            "Epoch 33/400\n",
            "14241/14241 - 20s - loss: 1.5988e-04 - val_loss: 2.7270e-04\n",
            "Epoch 34/400\n",
            "14241/14241 - 20s - loss: 1.6187e-04 - val_loss: 7.2631e-04\n",
            "Epoch 35/400\n",
            "14241/14241 - 20s - loss: 1.6145e-04 - val_loss: 1.8407e-04\n",
            "Epoch 36/400\n",
            "14241/14241 - 20s - loss: 1.6113e-04 - val_loss: 2.0264e-04\n",
            "Epoch 37/400\n",
            "14241/14241 - 20s - loss: 1.6048e-04 - val_loss: 0.0018\n",
            "Epoch 38/400\n",
            "14241/14241 - 21s - loss: 1.5985e-04 - val_loss: 3.9199e-04\n",
            "Epoch 39/400\n",
            "14241/14241 - 21s - loss: 1.5954e-04 - val_loss: 4.9539e-04\n",
            "Epoch 40/400\n",
            "14241/14241 - 27s - loss: 1.5587e-04 - val_loss: 3.5545e-04\n",
            "Epoch 41/400\n",
            "14241/14241 - 20s - loss: 1.5427e-04 - val_loss: 2.8980e-04\n",
            "Epoch 42/400\n",
            "14241/14241 - 20s - loss: 1.5423e-04 - val_loss: 2.6176e-04\n",
            "Epoch 43/400\n",
            "14241/14241 - 20s - loss: 1.5303e-04 - val_loss: 4.4117e-04\n",
            "Epoch 44/400\n",
            "14241/14241 - 20s - loss: 1.5149e-04 - val_loss: 3.8247e-04\n",
            "Epoch 45/400\n",
            "14241/14241 - 20s - loss: 1.5177e-04 - val_loss: 6.5649e-04\n",
            "Epoch 46/400\n",
            "14241/14241 - 20s - loss: 1.5042e-04 - val_loss: 5.1760e-04\n",
            "Epoch 47/400\n",
            "14241/14241 - 20s - loss: 1.5142e-04 - val_loss: 4.2647e-04\n",
            "Epoch 48/400\n",
            "14241/14241 - 20s - loss: 1.5144e-04 - val_loss: 4.1430e-04\n",
            "Epoch 49/400\n",
            "14241/14241 - 21s - loss: 1.5096e-04 - val_loss: 2.0258e-04\n",
            "Epoch 50/400\n",
            "14241/14241 - 20s - loss: 1.5068e-04 - val_loss: 0.0032\n",
            "Epoch 51/400\n",
            "14241/14241 - 20s - loss: 1.5080e-04 - val_loss: 0.0019\n",
            "Epoch 52/400\n",
            "14241/14241 - 21s - loss: 1.4990e-04 - val_loss: 0.0125\n",
            "Epoch 53/400\n",
            "14241/14241 - 21s - loss: 1.4979e-04 - val_loss: 3.7311e-04\n",
            "Epoch 54/400\n",
            "14241/14241 - 20s - loss: 1.4942e-04 - val_loss: 2.6926e-04\n",
            "Epoch 55/400\n",
            "14241/14241 - 20s - loss: 1.4960e-04 - val_loss: 1.5829e-04\n",
            "Epoch 56/400\n",
            "14241/14241 - 20s - loss: 1.5032e-04 - val_loss: 0.0014\n",
            "Epoch 57/400\n",
            "14241/14241 - 20s - loss: 1.5069e-04 - val_loss: 5.3516e-04\n",
            "Epoch 58/400\n",
            "14241/14241 - 20s - loss: 1.4990e-04 - val_loss: 0.0024\n",
            "Epoch 59/400\n",
            "14241/14241 - 20s - loss: 1.4963e-04 - val_loss: 0.0015\n",
            "Epoch 60/400\n",
            "14241/14241 - 20s - loss: 1.5011e-04 - val_loss: 0.0020\n",
            "Epoch 61/400\n",
            "14241/14241 - 20s - loss: 1.4932e-04 - val_loss: 2.3520e-04\n",
            "Epoch 62/400\n",
            "14241/14241 - 20s - loss: 1.4798e-04 - val_loss: 9.5099e-04\n",
            "Epoch 63/400\n",
            "14241/14241 - 20s - loss: 1.4875e-04 - val_loss: 0.0040\n",
            "Epoch 64/400\n",
            "14241/14241 - 20s - loss: 1.4922e-04 - val_loss: 9.6928e-04\n",
            "Epoch 65/400\n",
            "14241/14241 - 20s - loss: 1.4825e-04 - val_loss: 0.0126\n",
            "Epoch 66/400\n",
            "14241/14241 - 20s - loss: 1.4862e-04 - val_loss: 2.3175e-04\n",
            "Epoch 67/400\n",
            "14241/14241 - 20s - loss: 1.4832e-04 - val_loss: 1.0717e-04\n",
            "Epoch 68/400\n",
            "14241/14241 - 21s - loss: 1.4864e-04 - val_loss: 3.5009e-04\n",
            "Epoch 69/400\n",
            "14241/14241 - 20s - loss: 1.4764e-04 - val_loss: 7.4297e-04\n",
            "Epoch 70/400\n",
            "14241/14241 - 20s - loss: 1.4797e-04 - val_loss: 3.2376e-04\n",
            "Epoch 71/400\n",
            "14241/14241 - 20s - loss: 1.4792e-04 - val_loss: 3.3137e-04\n",
            "Epoch 72/400\n",
            "14241/14241 - 20s - loss: 1.4696e-04 - val_loss: 0.0012\n",
            "Epoch 73/400\n",
            "14241/14241 - 20s - loss: 1.4661e-04 - val_loss: 2.6922e-04\n",
            "Epoch 74/400\n",
            "14241/14241 - 20s - loss: 1.4715e-04 - val_loss: 0.0027\n",
            "Epoch 75/400\n",
            "14241/14241 - 20s - loss: 1.4794e-04 - val_loss: 2.9835e-04\n",
            "Epoch 76/400\n",
            "14241/14241 - 20s - loss: 1.4746e-04 - val_loss: 5.7852e-04\n",
            "Epoch 77/400\n",
            "14241/14241 - 20s - loss: 1.4572e-04 - val_loss: 4.1068e-04\n",
            "Epoch 78/400\n",
            "14241/14241 - 20s - loss: 1.4679e-04 - val_loss: 0.0011\n",
            "Epoch 79/400\n",
            "14241/14241 - 20s - loss: 1.4664e-04 - val_loss: 5.4595e-04\n",
            "Epoch 80/400\n",
            "14241/14241 - 20s - loss: 1.4653e-04 - val_loss: 0.0013\n",
            "Epoch 81/400\n",
            "14241/14241 - 20s - loss: 1.4603e-04 - val_loss: 3.5584e-04\n",
            "Epoch 82/400\n",
            "14241/14241 - 20s - loss: 1.4657e-04 - val_loss: 0.0015\n",
            "Epoch 83/400\n",
            "14241/14241 - 21s - loss: 1.4641e-04 - val_loss: 0.0011\n",
            "Epoch 84/400\n",
            "14241/14241 - 21s - loss: 1.4606e-04 - val_loss: 6.8587e-04\n",
            "Epoch 85/400\n",
            "14241/14241 - 20s - loss: 1.4605e-04 - val_loss: 1.8395e-04\n",
            "Epoch 86/400\n",
            "14241/14241 - 20s - loss: 1.4569e-04 - val_loss: 8.5108e-04\n",
            "Epoch 87/400\n",
            "14241/14241 - 21s - loss: 1.4660e-04 - val_loss: 4.2713e-04\n",
            "Epoch 88/400\n",
            "14241/14241 - 21s - loss: 1.4620e-04 - val_loss: 5.0775e-04\n",
            "Epoch 89/400\n",
            "14241/14241 - 20s - loss: 1.4584e-04 - val_loss: 4.3567e-04\n",
            "Epoch 90/400\n",
            "14241/14241 - 21s - loss: 1.4634e-04 - val_loss: 1.7796e-04\n",
            "Epoch 91/400\n",
            "14241/14241 - 20s - loss: 1.4507e-04 - val_loss: 9.1819e-04\n",
            "Epoch 92/400\n",
            "14241/14241 - 20s - loss: 1.4559e-04 - val_loss: 0.0038\n",
            "Epoch 93/400\n",
            "14241/14241 - 20s - loss: 1.4573e-04 - val_loss: 0.0019\n",
            "Epoch 94/400\n",
            "14241/14241 - 20s - loss: 1.4655e-04 - val_loss: 2.6129e-04\n",
            "Epoch 95/400\n",
            "14241/14241 - 20s - loss: 1.4582e-04 - val_loss: 4.4836e-04\n",
            "Epoch 96/400\n",
            "14241/14241 - 20s - loss: 1.4468e-04 - val_loss: 5.0915e-04\n",
            "Epoch 97/400\n",
            "14241/14241 - 20s - loss: 1.4505e-04 - val_loss: 3.5426e-04\n",
            "Epoch 98/400\n",
            "14241/14241 - 21s - loss: 1.4407e-04 - val_loss: 8.7933e-04\n",
            "Epoch 99/400\n",
            "14241/14241 - 20s - loss: 1.4462e-04 - val_loss: 0.0030\n",
            "Epoch 100/400\n",
            "14241/14241 - 20s - loss: 1.4471e-04 - val_loss: 0.0020\n",
            "Epoch 101/400\n",
            "14241/14241 - 20s - loss: 1.4445e-04 - val_loss: 3.7984e-04\n",
            "Epoch 102/400\n",
            "14241/14241 - 20s - loss: 1.4530e-04 - val_loss: 4.1672e-04\n",
            "Epoch 103/400\n",
            "14241/14241 - 20s - loss: 1.4545e-04 - val_loss: 0.0103\n",
            "Epoch 104/400\n",
            "14241/14241 - 20s - loss: 1.4515e-04 - val_loss: 3.9219e-04\n",
            "Epoch 105/400\n",
            "14241/14241 - 20s - loss: 1.4522e-04 - val_loss: 2.1185e-04\n",
            "Epoch 106/400\n",
            "14241/14241 - 20s - loss: 1.4477e-04 - val_loss: 7.6094e-04\n",
            "Epoch 107/400\n",
            "14241/14241 - 20s - loss: 1.4454e-04 - val_loss: 5.4674e-04\n",
            "Epoch 108/400\n",
            "14241/14241 - 20s - loss: 1.4502e-04 - val_loss: 0.0012\n",
            "Epoch 109/400\n",
            "14241/14241 - 20s - loss: 1.4475e-04 - val_loss: 0.0013\n",
            "Epoch 110/400\n",
            "14241/14241 - 20s - loss: 1.4304e-04 - val_loss: 7.5986e-04\n",
            "Epoch 111/400\n",
            "14241/14241 - 20s - loss: 1.4455e-04 - val_loss: 0.0013\n",
            "Epoch 112/400\n",
            "14241/14241 - 20s - loss: 1.4407e-04 - val_loss: 8.9959e-04\n",
            "Epoch 113/400\n",
            "14241/14241 - 21s - loss: 1.4266e-04 - val_loss: 3.5836e-04\n",
            "Epoch 114/400\n",
            "14241/14241 - 21s - loss: 1.4327e-04 - val_loss: 3.0382e-04\n",
            "Epoch 115/400\n",
            "14241/14241 - 20s - loss: 1.4319e-04 - val_loss: 2.3001e-04\n",
            "Epoch 116/400\n",
            "14241/14241 - 20s - loss: 1.4226e-04 - val_loss: 4.6305e-04\n",
            "Epoch 117/400\n",
            "14241/14241 - 20s - loss: 1.4246e-04 - val_loss: 2.1530e-04\n",
            "Epoch 118/400\n",
            "14241/14241 - 20s - loss: 1.4246e-04 - val_loss: 0.0013\n",
            "Epoch 119/400\n",
            "14241/14241 - 20s - loss: 1.4323e-04 - val_loss: 3.5367e-04\n",
            "Epoch 120/400\n",
            "14241/14241 - 20s - loss: 1.4369e-04 - val_loss: 1.9176e-04\n",
            "Epoch 121/400\n",
            "14241/14241 - 20s - loss: 1.4244e-04 - val_loss: 1.2625e-04\n",
            "Epoch 122/400\n",
            "14241/14241 - 20s - loss: 1.4299e-04 - val_loss: 5.3107e-04\n",
            "Epoch 123/400\n",
            "14241/14241 - 20s - loss: 1.4358e-04 - val_loss: 6.5211e-04\n",
            "Epoch 124/400\n",
            "14241/14241 - 20s - loss: 1.4343e-04 - val_loss: 9.4180e-04\n",
            "Epoch 125/400\n",
            "14241/14241 - 20s - loss: 1.4228e-04 - val_loss: 2.8746e-04\n",
            "Epoch 126/400\n",
            "14241/14241 - 20s - loss: 1.4298e-04 - val_loss: 2.0419e-04\n",
            "Epoch 127/400\n",
            "14241/14241 - 21s - loss: 1.4420e-04 - val_loss: 7.6716e-04\n",
            "Epoch 128/400\n",
            "14241/14241 - 21s - loss: 1.4334e-04 - val_loss: 7.3805e-04\n",
            "Epoch 129/400\n",
            "14241/14241 - 20s - loss: 1.4250e-04 - val_loss: 1.8828e-04\n",
            "Epoch 130/400\n",
            "14241/14241 - 22s - loss: 1.4328e-04 - val_loss: 0.0012\n",
            "Epoch 131/400\n",
            "14241/14241 - 20s - loss: 1.4275e-04 - val_loss: 2.8673e-04\n",
            "Epoch 132/400\n",
            "14241/14241 - 20s - loss: 1.4249e-04 - val_loss: 4.1658e-04\n",
            "Epoch 133/400\n",
            "14241/14241 - 20s - loss: 1.4207e-04 - val_loss: 0.0023\n",
            "Epoch 134/400\n",
            "14241/14241 - 20s - loss: 1.4323e-04 - val_loss: 2.6087e-04\n",
            "Epoch 135/400\n",
            "14241/14241 - 20s - loss: 1.4429e-04 - val_loss: 0.0162\n",
            "Epoch 136/400\n",
            "14241/14241 - 20s - loss: 1.4338e-04 - val_loss: 2.0244e-04\n",
            "Epoch 137/400\n",
            "14241/14241 - 20s - loss: 1.4312e-04 - val_loss: 6.5247e-04\n",
            "Epoch 138/400\n",
            "14241/14241 - 20s - loss: 1.4239e-04 - val_loss: 0.0014\n",
            "Epoch 139/400\n",
            "14241/14241 - 20s - loss: 1.4209e-04 - val_loss: 1.6524e-04\n",
            "Epoch 140/400\n",
            "14241/14241 - 20s - loss: 1.4298e-04 - val_loss: 2.9709e-04\n",
            "Epoch 141/400\n",
            "14241/14241 - 20s - loss: 1.4249e-04 - val_loss: 6.0759e-04\n",
            "Epoch 142/400\n",
            "14241/14241 - 20s - loss: 1.4263e-04 - val_loss: 5.2000e-04\n",
            "Epoch 143/400\n",
            "14241/14241 - 21s - loss: 1.4091e-04 - val_loss: 2.6096e-04\n",
            "Epoch 144/400\n",
            "14241/14241 - 21s - loss: 1.4192e-04 - val_loss: 0.0015\n",
            "Epoch 145/400\n",
            "14241/14241 - 21s - loss: 1.4200e-04 - val_loss: 8.5901e-04\n",
            "Epoch 146/400\n",
            "14241/14241 - 21s - loss: 1.4227e-04 - val_loss: 0.0040\n",
            "Epoch 147/400\n",
            "14241/14241 - 20s - loss: 1.4136e-04 - val_loss: 5.3756e-04\n",
            "Epoch 148/400\n",
            "14241/14241 - 21s - loss: 1.4194e-04 - val_loss: 0.0010\n",
            "Epoch 149/400\n",
            "14241/14241 - 20s - loss: 1.4245e-04 - val_loss: 0.0024\n",
            "Epoch 150/400\n",
            "14241/14241 - 20s - loss: 1.4152e-04 - val_loss: 9.7206e-04\n",
            "Epoch 151/400\n",
            "14241/14241 - 20s - loss: 1.4093e-04 - val_loss: 0.0010\n",
            "Epoch 152/400\n",
            "14241/14241 - 21s - loss: 1.4151e-04 - val_loss: 4.2423e-04\n",
            "Epoch 153/400\n",
            "14241/14241 - 20s - loss: 1.4221e-04 - val_loss: 5.2388e-04\n",
            "Epoch 154/400\n",
            "14241/14241 - 20s - loss: 1.4310e-04 - val_loss: 0.0012\n",
            "Epoch 155/400\n",
            "14241/14241 - 20s - loss: 1.4176e-04 - val_loss: 2.8337e-04\n",
            "Epoch 156/400\n",
            "14241/14241 - 21s - loss: 1.4247e-04 - val_loss: 0.0010\n",
            "Epoch 157/400\n",
            "14241/14241 - 20s - loss: 1.4057e-04 - val_loss: 2.4447e-04\n",
            "Epoch 158/400\n",
            "14241/14241 - 21s - loss: 1.4326e-04 - val_loss: 2.2129e-04\n",
            "Epoch 159/400\n",
            "14241/14241 - 20s - loss: 1.4145e-04 - val_loss: 0.0022\n",
            "Epoch 160/400\n",
            "14241/14241 - 21s - loss: 1.4273e-04 - val_loss: 2.3719e-04\n",
            "Epoch 161/400\n",
            "14241/14241 - 20s - loss: 1.4171e-04 - val_loss: 0.0018\n",
            "Epoch 162/400\n",
            "14241/14241 - 20s - loss: 1.4207e-04 - val_loss: 0.0014\n",
            "Epoch 163/400\n",
            "14241/14241 - 20s - loss: 1.4047e-04 - val_loss: 4.7771e-04\n",
            "Epoch 164/400\n",
            "14241/14241 - 20s - loss: 1.4117e-04 - val_loss: 9.8906e-04\n",
            "Epoch 165/400\n",
            "14241/14241 - 20s - loss: 1.4152e-04 - val_loss: 0.0019\n",
            "Epoch 166/400\n",
            "14241/14241 - 20s - loss: 1.4123e-04 - val_loss: 3.9404e-04\n",
            "Epoch 167/400\n",
            "14241/14241 - 20s - loss: 1.4101e-04 - val_loss: 9.4138e-05\n",
            "Epoch 168/400\n",
            "14241/14241 - 20s - loss: 1.4140e-04 - val_loss: 0.0012\n",
            "Epoch 169/400\n",
            "14241/14241 - 20s - loss: 1.4205e-04 - val_loss: 0.0081\n",
            "Epoch 170/400\n",
            "14241/14241 - 20s - loss: 1.4114e-04 - val_loss: 5.2558e-04\n",
            "Epoch 171/400\n",
            "14241/14241 - 20s - loss: 1.4069e-04 - val_loss: 0.0013\n",
            "Epoch 172/400\n",
            "14241/14241 - 20s - loss: 1.4016e-04 - val_loss: 0.0017\n",
            "Epoch 173/400\n",
            "14241/14241 - 20s - loss: 1.4164e-04 - val_loss: 5.6068e-04\n",
            "Epoch 174/400\n",
            "14241/14241 - 20s - loss: 1.4206e-04 - val_loss: 0.0011\n",
            "Epoch 175/400\n",
            "14241/14241 - 20s - loss: 1.4163e-04 - val_loss: 2.2224e-04\n",
            "Epoch 176/400\n",
            "14241/14241 - 21s - loss: 1.4185e-04 - val_loss: 2.1811e-04\n",
            "Epoch 177/400\n",
            "14241/14241 - 20s - loss: 1.4119e-04 - val_loss: 0.0011\n",
            "Epoch 178/400\n",
            "14241/14241 - 20s - loss: 1.4030e-04 - val_loss: 4.2877e-04\n",
            "Epoch 179/400\n",
            "14241/14241 - 20s - loss: 1.4126e-04 - val_loss: 5.9512e-04\n",
            "Epoch 180/400\n",
            "14241/14241 - 20s - loss: 1.4025e-04 - val_loss: 4.4014e-04\n",
            "Epoch 181/400\n",
            "14241/14241 - 20s - loss: 1.4136e-04 - val_loss: 5.5043e-04\n",
            "Epoch 182/400\n",
            "14241/14241 - 20s - loss: 1.4173e-04 - val_loss: 8.4301e-04\n",
            "Epoch 183/400\n",
            "14241/14241 - 20s - loss: 1.4036e-04 - val_loss: 7.8331e-04\n",
            "Epoch 184/400\n",
            "14241/14241 - 20s - loss: 1.4015e-04 - val_loss: 5.3911e-04\n",
            "Epoch 185/400\n",
            "14241/14241 - 20s - loss: 1.3963e-04 - val_loss: 0.0021\n",
            "Epoch 186/400\n",
            "14241/14241 - 20s - loss: 1.3982e-04 - val_loss: 0.0032\n",
            "Epoch 187/400\n",
            "14241/14241 - 20s - loss: 1.3976e-04 - val_loss: 8.9222e-04\n",
            "Epoch 188/400\n",
            "14241/14241 - 20s - loss: 1.4072e-04 - val_loss: 0.0017\n",
            "Epoch 189/400\n",
            "14241/14241 - 20s - loss: 1.3970e-04 - val_loss: 0.0017\n",
            "Epoch 190/400\n",
            "14241/14241 - 20s - loss: 1.4113e-04 - val_loss: 2.4857e-04\n",
            "Epoch 191/400\n",
            "14241/14241 - 20s - loss: 1.4091e-04 - val_loss: 3.7579e-04\n",
            "Epoch 192/400\n",
            "14241/14241 - 20s - loss: 1.3979e-04 - val_loss: 2.3758e-04\n",
            "Epoch 193/400\n",
            "14241/14241 - 20s - loss: 1.4104e-04 - val_loss: 6.6945e-04\n",
            "Epoch 194/400\n",
            "14241/14241 - 20s - loss: 1.3854e-04 - val_loss: 6.4577e-04\n",
            "Epoch 195/400\n",
            "14241/14241 - 20s - loss: 1.4026e-04 - val_loss: 7.7097e-04\n",
            "Epoch 196/400\n",
            "14241/14241 - 20s - loss: 1.3890e-04 - val_loss: 4.3310e-04\n",
            "Epoch 197/400\n",
            "14241/14241 - 20s - loss: 1.4101e-04 - val_loss: 2.1495e-04\n",
            "Epoch 198/400\n",
            "14241/14241 - 20s - loss: 1.4071e-04 - val_loss: 9.5406e-04\n",
            "Epoch 199/400\n",
            "14241/14241 - 20s - loss: 1.4014e-04 - val_loss: 0.0022\n",
            "Epoch 200/400\n",
            "14241/14241 - 20s - loss: 1.4125e-04 - val_loss: 6.0772e-04\n",
            "Epoch 201/400\n",
            "14241/14241 - 20s - loss: 1.3987e-04 - val_loss: 2.1029e-04\n",
            "Epoch 202/400\n",
            "14241/14241 - 20s - loss: 1.3911e-04 - val_loss: 4.3657e-04\n",
            "Epoch 203/400\n",
            "14241/14241 - 20s - loss: 1.3984e-04 - val_loss: 4.8364e-04\n",
            "Epoch 204/400\n",
            "14241/14241 - 20s - loss: 1.3970e-04 - val_loss: 2.9584e-04\n",
            "Epoch 205/400\n",
            "14241/14241 - 20s - loss: 1.3876e-04 - val_loss: 5.3070e-04\n",
            "Epoch 206/400\n",
            "14241/14241 - 20s - loss: 1.4010e-04 - val_loss: 4.6228e-04\n",
            "Epoch 207/400\n",
            "14241/14241 - 21s - loss: 1.3873e-04 - val_loss: 0.0015\n",
            "Epoch 208/400\n",
            "14241/14241 - 20s - loss: 1.3948e-04 - val_loss: 1.4182e-04\n",
            "Epoch 209/400\n",
            "14241/14241 - 20s - loss: 1.3984e-04 - val_loss: 0.0033\n",
            "Epoch 210/400\n",
            "14241/14241 - 20s - loss: 1.3976e-04 - val_loss: 4.6760e-04\n",
            "Epoch 211/400\n",
            "14241/14241 - 20s - loss: 1.3968e-04 - val_loss: 2.9652e-04\n",
            "Epoch 212/400\n",
            "14241/14241 - 20s - loss: 1.3940e-04 - val_loss: 0.0034\n",
            "Epoch 213/400\n",
            "14241/14241 - 20s - loss: 1.3823e-04 - val_loss: 0.0192\n",
            "Epoch 214/400\n",
            "14241/14241 - 20s - loss: 1.3924e-04 - val_loss: 6.8333e-04\n",
            "Epoch 215/400\n",
            "14241/14241 - 20s - loss: 1.4142e-04 - val_loss: 4.3491e-04\n",
            "Epoch 216/400\n",
            "14241/14241 - 20s - loss: 1.3814e-04 - val_loss: 0.0055\n",
            "Epoch 217/400\n",
            "14241/14241 - 20s - loss: 1.3984e-04 - val_loss: 4.9550e-04\n",
            "Epoch 218/400\n",
            "14241/14241 - 20s - loss: 1.3969e-04 - val_loss: 3.0080e-04\n",
            "Epoch 219/400\n",
            "14241/14241 - 20s - loss: 1.3908e-04 - val_loss: 0.0015\n",
            "Epoch 220/400\n",
            "14241/14241 - 21s - loss: 1.3963e-04 - val_loss: 2.5992e-04\n",
            "Epoch 221/400\n",
            "14241/14241 - 20s - loss: 1.3875e-04 - val_loss: 0.0015\n",
            "Epoch 222/400\n",
            "14241/14241 - 20s - loss: 1.3926e-04 - val_loss: 2.0925e-04\n",
            "Epoch 223/400\n",
            "14241/14241 - 21s - loss: 1.4059e-04 - val_loss: 0.0897\n",
            "Epoch 224/400\n",
            "14241/14241 - 20s - loss: 1.4000e-04 - val_loss: 1.2879e-04\n",
            "Epoch 225/400\n",
            "14241/14241 - 20s - loss: 1.3908e-04 - val_loss: 1.4891e-04\n",
            "Epoch 226/400\n",
            "14241/14241 - 20s - loss: 1.3844e-04 - val_loss: 2.8408e-04\n",
            "Epoch 227/400\n",
            "14241/14241 - 20s - loss: 1.3860e-04 - val_loss: 2.0321e-04\n",
            "Epoch 228/400\n",
            "14241/14241 - 20s - loss: 1.3858e-04 - val_loss: 2.1601e-04\n",
            "Epoch 229/400\n",
            "14241/14241 - 20s - loss: 1.3834e-04 - val_loss: 6.4242e-04\n",
            "Epoch 230/400\n",
            "14241/14241 - 20s - loss: 1.3817e-04 - val_loss: 0.0018\n",
            "Epoch 231/400\n",
            "14241/14241 - 20s - loss: 1.3835e-04 - val_loss: 0.0014\n",
            "Epoch 232/400\n",
            "14241/14241 - 20s - loss: 1.3896e-04 - val_loss: 0.0013\n",
            "Epoch 233/400\n",
            "14241/14241 - 20s - loss: 1.3867e-04 - val_loss: 9.3458e-04\n",
            "Epoch 234/400\n",
            "14241/14241 - 20s - loss: 1.3916e-04 - val_loss: 0.0010\n",
            "Epoch 235/400\n",
            "14241/14241 - 20s - loss: 1.3994e-04 - val_loss: 8.3718e-04\n",
            "Epoch 236/400\n",
            "14241/14241 - 20s - loss: 1.3979e-04 - val_loss: 2.9870e-04\n",
            "Epoch 237/400\n",
            "14241/14241 - 20s - loss: 1.3744e-04 - val_loss: 1.2383e-04\n",
            "Epoch 238/400\n",
            "14241/14241 - 20s - loss: 1.3922e-04 - val_loss: 0.0418\n",
            "Epoch 239/400\n",
            "14241/14241 - 20s - loss: 1.3858e-04 - val_loss: 1.2504e-04\n",
            "Epoch 240/400\n",
            "14241/14241 - 20s - loss: 1.3959e-04 - val_loss: 0.0014\n",
            "Epoch 241/400\n",
            "14241/14241 - 20s - loss: 1.3797e-04 - val_loss: 1.4795e-04\n",
            "Epoch 242/400\n",
            "14241/14241 - 20s - loss: 1.3732e-04 - val_loss: 5.9926e-04\n",
            "Epoch 243/400\n",
            "14241/14241 - 20s - loss: 1.3905e-04 - val_loss: 0.0014\n",
            "Epoch 244/400\n",
            "14241/14241 - 20s - loss: 1.3932e-04 - val_loss: 0.0047\n",
            "Epoch 245/400\n",
            "14241/14241 - 20s - loss: 1.3924e-04 - val_loss: 4.0432e-04\n",
            "Epoch 246/400\n",
            "14241/14241 - 20s - loss: 1.3904e-04 - val_loss: 1.8945e-04\n",
            "Epoch 247/400\n",
            "14241/14241 - 20s - loss: 1.3782e-04 - val_loss: 4.6931e-04\n",
            "Epoch 248/400\n",
            "14241/14241 - 20s - loss: 1.3860e-04 - val_loss: 2.3880e-04\n",
            "Epoch 249/400\n",
            "14241/14241 - 20s - loss: 1.3843e-04 - val_loss: 4.1775e-04\n",
            "Epoch 250/400\n",
            "14241/14241 - 20s - loss: 1.3789e-04 - val_loss: 5.1076e-04\n",
            "Epoch 251/400\n",
            "14241/14241 - 20s - loss: 1.3891e-04 - val_loss: 0.0163\n",
            "Epoch 252/400\n",
            "14241/14241 - 20s - loss: 1.3841e-04 - val_loss: 7.0735e-04\n",
            "Epoch 253/400\n",
            "14241/14241 - 20s - loss: 1.3941e-04 - val_loss: 5.8483e-04\n",
            "Epoch 254/400\n",
            "14241/14241 - 20s - loss: 1.3767e-04 - val_loss: 4.5341e-04\n",
            "Epoch 255/400\n",
            "14241/14241 - 20s - loss: 1.3793e-04 - val_loss: 9.3280e-04\n",
            "Epoch 256/400\n",
            "14241/14241 - 20s - loss: 1.3854e-04 - val_loss: 6.5332e-04\n",
            "Epoch 257/400\n",
            "14241/14241 - 20s - loss: 1.3895e-04 - val_loss: 2.2324e-04\n",
            "Epoch 258/400\n",
            "14241/14241 - 20s - loss: 1.3802e-04 - val_loss: 4.0831e-04\n",
            "Epoch 259/400\n",
            "14241/14241 - 20s - loss: 1.3903e-04 - val_loss: 2.7468e-04\n",
            "Epoch 260/400\n",
            "14241/14241 - 20s - loss: 1.3788e-04 - val_loss: 1.7480e-04\n",
            "Epoch 261/400\n",
            "14241/14241 - 20s - loss: 1.3881e-04 - val_loss: 1.8088e-04\n",
            "Epoch 262/400\n",
            "14241/14241 - 20s - loss: 1.3813e-04 - val_loss: 6.1275e-04\n",
            "Epoch 263/400\n",
            "14241/14241 - 20s - loss: 1.3856e-04 - val_loss: 0.0015\n",
            "Epoch 264/400\n",
            "14241/14241 - 20s - loss: 1.3752e-04 - val_loss: 7.8250e-04\n",
            "Epoch 265/400\n",
            "14241/14241 - 20s - loss: 1.3848e-04 - val_loss: 5.6174e-04\n",
            "Epoch 266/400\n",
            "14241/14241 - 20s - loss: 1.3893e-04 - val_loss: 4.2514e-04\n",
            "Epoch 267/400\n",
            "14241/14241 - 20s - loss: 1.3892e-04 - val_loss: 3.6139e-04\n",
            "Epoch 268/400\n",
            "14241/14241 - 20s - loss: 1.3837e-04 - val_loss: 7.9330e-04\n",
            "Epoch 269/400\n",
            "14241/14241 - 20s - loss: 1.3829e-04 - val_loss: 1.3850e-04\n",
            "Epoch 270/400\n",
            "14241/14241 - 20s - loss: 1.3662e-04 - val_loss: 0.0011\n",
            "Epoch 271/400\n",
            "14241/14241 - 20s - loss: 1.3774e-04 - val_loss: 7.0540e-04\n",
            "Epoch 272/400\n",
            "14241/14241 - 20s - loss: 1.3729e-04 - val_loss: 6.6606e-04\n",
            "Epoch 273/400\n",
            "14241/14241 - 20s - loss: 1.3737e-04 - val_loss: 6.8846e-04\n",
            "Epoch 274/400\n",
            "14241/14241 - 20s - loss: 1.3855e-04 - val_loss: 2.1902e-04\n",
            "Epoch 275/400\n",
            "14241/14241 - 20s - loss: 1.3723e-04 - val_loss: 0.0022\n",
            "Epoch 276/400\n",
            "14241/14241 - 20s - loss: 1.3846e-04 - val_loss: 0.0400\n",
            "Epoch 277/400\n",
            "14241/14241 - 20s - loss: 1.3947e-04 - val_loss: 0.0022\n",
            "Epoch 278/400\n",
            "14241/14241 - 20s - loss: 1.3690e-04 - val_loss: 7.9223e-04\n",
            "Epoch 279/400\n",
            "14241/14241 - 20s - loss: 1.3918e-04 - val_loss: 4.3755e-04\n",
            "Epoch 280/400\n",
            "14241/14241 - 20s - loss: 1.3827e-04 - val_loss: 0.0017\n",
            "Epoch 281/400\n",
            "14241/14241 - 20s - loss: 1.3820e-04 - val_loss: 3.4859e-04\n",
            "Epoch 282/400\n",
            "14241/14241 - 20s - loss: 1.3749e-04 - val_loss: 0.0078\n",
            "Epoch 283/400\n",
            "14241/14241 - 21s - loss: 1.3793e-04 - val_loss: 0.0032\n",
            "Epoch 284/400\n",
            "14241/14241 - 20s - loss: 1.3794e-04 - val_loss: 0.0068\n",
            "Epoch 285/400\n",
            "14241/14241 - 20s - loss: 1.3907e-04 - val_loss: 8.8532e-04\n",
            "Epoch 286/400\n",
            "14241/14241 - 20s - loss: 1.3794e-04 - val_loss: 0.0016\n",
            "Epoch 287/400\n",
            "14241/14241 - 20s - loss: 1.3758e-04 - val_loss: 1.6142e-04\n",
            "Epoch 288/400\n",
            "14241/14241 - 20s - loss: 1.3840e-04 - val_loss: 1.8125e-04\n",
            "Epoch 289/400\n",
            "14241/14241 - 20s - loss: 1.3841e-04 - val_loss: 9.2840e-04\n",
            "Epoch 290/400\n",
            "14241/14241 - 20s - loss: 1.3745e-04 - val_loss: 4.4984e-04\n",
            "Epoch 291/400\n",
            "14241/14241 - 20s - loss: 1.3853e-04 - val_loss: 2.5989e-04\n",
            "Epoch 292/400\n",
            "14241/14241 - 20s - loss: 1.3742e-04 - val_loss: 3.1358e-04\n",
            "Epoch 293/400\n",
            "14241/14241 - 19s - loss: 1.3815e-04 - val_loss: 0.0059\n",
            "Epoch 294/400\n",
            "14241/14241 - 19s - loss: 1.3794e-04 - val_loss: 4.9100e-04\n",
            "Epoch 295/400\n",
            "14241/14241 - 20s - loss: 1.3858e-04 - val_loss: 6.2668e-04\n",
            "Epoch 296/400\n",
            "14241/14241 - 20s - loss: 1.3850e-04 - val_loss: 0.0099\n",
            "Epoch 297/400\n",
            "14241/14241 - 20s - loss: 1.3773e-04 - val_loss: 3.4246e-04\n",
            "Epoch 298/400\n",
            "14241/14241 - 19s - loss: 1.3841e-04 - val_loss: 0.0012\n",
            "Epoch 299/400\n",
            "14241/14241 - 19s - loss: 1.3861e-04 - val_loss: 0.0014\n",
            "Epoch 300/400\n",
            "14241/14241 - 19s - loss: 1.3834e-04 - val_loss: 1.6920e-04\n",
            "Epoch 301/400\n",
            "14241/14241 - 20s - loss: 1.3749e-04 - val_loss: 7.6960e-04\n",
            "Epoch 302/400\n",
            "14241/14241 - 19s - loss: 1.3872e-04 - val_loss: 5.8737e-04\n",
            "Epoch 303/400\n",
            "14241/14241 - 20s - loss: 1.3855e-04 - val_loss: 3.3513e-04\n",
            "Epoch 304/400\n",
            "14241/14241 - 19s - loss: 1.3783e-04 - val_loss: 2.9904e-04\n",
            "Epoch 305/400\n",
            "14241/14241 - 20s - loss: 1.3723e-04 - val_loss: 5.8622e-04\n",
            "Epoch 306/400\n",
            "14241/14241 - 20s - loss: 1.3687e-04 - val_loss: 1.9547e-04\n",
            "Epoch 307/400\n",
            "14241/14241 - 19s - loss: 1.3751e-04 - val_loss: 0.0153\n",
            "Epoch 308/400\n",
            "14241/14241 - 19s - loss: 1.3737e-04 - val_loss: 4.4153e-04\n",
            "Epoch 309/400\n",
            "14241/14241 - 20s - loss: 1.3605e-04 - val_loss: 0.0037\n",
            "Epoch 310/400\n",
            "14241/14241 - 20s - loss: 1.3787e-04 - val_loss: 0.0025\n",
            "Epoch 311/400\n",
            "14241/14241 - 20s - loss: 1.3720e-04 - val_loss: 2.9584e-04\n",
            "Epoch 312/400\n",
            "14241/14241 - 20s - loss: 1.3712e-04 - val_loss: 0.0214\n",
            "Epoch 313/400\n",
            "14241/14241 - 20s - loss: 1.3719e-04 - val_loss: 3.3919e-04\n",
            "Epoch 314/400\n",
            "14241/14241 - 20s - loss: 1.3709e-04 - val_loss: 3.5712e-04\n",
            "Epoch 315/400\n",
            "14241/14241 - 20s - loss: 1.3719e-04 - val_loss: 7.2003e-04\n",
            "Epoch 316/400\n",
            "14241/14241 - 20s - loss: 1.3730e-04 - val_loss: 5.3431e-04\n",
            "Epoch 317/400\n",
            "14241/14241 - 20s - loss: 1.3755e-04 - val_loss: 1.8661e-04\n",
            "Epoch 318/400\n",
            "14241/14241 - 20s - loss: 1.3771e-04 - val_loss: 2.3498e-04\n",
            "Epoch 319/400\n",
            "14241/14241 - 20s - loss: 1.3702e-04 - val_loss: 4.2432e-04\n",
            "Epoch 320/400\n",
            "14241/14241 - 19s - loss: 1.3744e-04 - val_loss: 4.8181e-04\n",
            "Epoch 321/400\n",
            "14241/14241 - 19s - loss: 1.3670e-04 - val_loss: 4.3211e-04\n",
            "Epoch 322/400\n",
            "14241/14241 - 20s - loss: 1.3682e-04 - val_loss: 0.0020\n",
            "Epoch 323/400\n",
            "14241/14241 - 20s - loss: 1.3774e-04 - val_loss: 1.7246e-04\n",
            "Epoch 324/400\n",
            "14241/14241 - 20s - loss: 1.3624e-04 - val_loss: 0.0011\n",
            "Epoch 325/400\n",
            "14241/14241 - 20s - loss: 1.3706e-04 - val_loss: 8.3241e-04\n",
            "Epoch 326/400\n",
            "14241/14241 - 20s - loss: 1.3611e-04 - val_loss: 0.0019\n",
            "Epoch 327/400\n",
            "14241/14241 - 19s - loss: 1.3687e-04 - val_loss: 2.3256e-04\n",
            "Epoch 328/400\n",
            "14241/14241 - 20s - loss: 1.3726e-04 - val_loss: 2.5691e-04\n",
            "Epoch 329/400\n",
            "14241/14241 - 20s - loss: 1.3664e-04 - val_loss: 7.1004e-04\n",
            "Epoch 330/400\n",
            "14241/14241 - 19s - loss: 1.3723e-04 - val_loss: 5.4629e-04\n",
            "Epoch 331/400\n",
            "14241/14241 - 19s - loss: 1.3797e-04 - val_loss: 4.6764e-04\n",
            "Epoch 332/400\n",
            "14241/14241 - 19s - loss: 1.3777e-04 - val_loss: 8.0528e-04\n",
            "Epoch 333/400\n",
            "14241/14241 - 20s - loss: 1.3772e-04 - val_loss: 9.0987e-04\n",
            "Epoch 334/400\n",
            "14241/14241 - 20s - loss: 1.3711e-04 - val_loss: 3.4994e-04\n",
            "Epoch 335/400\n",
            "14241/14241 - 20s - loss: 1.3715e-04 - val_loss: 5.2577e-04\n",
            "Epoch 336/400\n",
            "14241/14241 - 20s - loss: 1.3675e-04 - val_loss: 0.0085\n",
            "Epoch 337/400\n",
            "14241/14241 - 20s - loss: 1.3672e-04 - val_loss: 0.0023\n",
            "Epoch 338/400\n",
            "14241/14241 - 20s - loss: 1.3578e-04 - val_loss: 2.2739e-04\n",
            "Epoch 339/400\n",
            "14241/14241 - 20s - loss: 1.3772e-04 - val_loss: 0.0022\n",
            "Epoch 340/400\n",
            "14241/14241 - 19s - loss: 1.3729e-04 - val_loss: 0.0021\n",
            "Epoch 341/400\n",
            "14241/14241 - 20s - loss: 1.3619e-04 - val_loss: 0.0021\n",
            "Epoch 342/400\n",
            "14241/14241 - 20s - loss: 1.3593e-04 - val_loss: 0.0316\n",
            "Epoch 343/400\n",
            "14241/14241 - 20s - loss: 1.3613e-04 - val_loss: 4.9526e-04\n",
            "Epoch 344/400\n",
            "14241/14241 - 20s - loss: 1.3735e-04 - val_loss: 2.1339e-04\n",
            "Epoch 345/400\n",
            "14241/14241 - 20s - loss: 1.3666e-04 - val_loss: 3.1421e-04\n",
            "Epoch 346/400\n",
            "14241/14241 - 20s - loss: 1.3677e-04 - val_loss: 4.2822e-04\n",
            "Epoch 347/400\n",
            "14241/14241 - 20s - loss: 1.3584e-04 - val_loss: 9.8929e-04\n",
            "Epoch 348/400\n",
            "14241/14241 - 20s - loss: 1.3880e-04 - val_loss: 7.1801e-04\n",
            "Epoch 349/400\n",
            "14241/14241 - 20s - loss: 1.3772e-04 - val_loss: 1.4464e-04\n",
            "Epoch 350/400\n",
            "14241/14241 - 20s - loss: 1.3734e-04 - val_loss: 4.2919e-04\n",
            "Epoch 351/400\n",
            "14241/14241 - 20s - loss: 1.3744e-04 - val_loss: 0.0016\n",
            "Epoch 352/400\n",
            "14241/14241 - 20s - loss: 1.3633e-04 - val_loss: 2.6896e-04\n",
            "Epoch 353/400\n",
            "14241/14241 - 19s - loss: 1.3665e-04 - val_loss: 1.7119e-04\n",
            "Epoch 354/400\n",
            "14241/14241 - 21s - loss: 1.3741e-04 - val_loss: 2.9056e-04\n",
            "Epoch 355/400\n",
            "14241/14241 - 21s - loss: 1.3644e-04 - val_loss: 7.5274e-04\n",
            "Epoch 356/400\n",
            "14241/14241 - 21s - loss: 1.3765e-04 - val_loss: 2.2974e-04\n",
            "Epoch 357/400\n",
            "14241/14241 - 21s - loss: 1.3548e-04 - val_loss: 2.6445e-04\n",
            "Epoch 358/400\n",
            "14241/14241 - 21s - loss: 1.3677e-04 - val_loss: 7.0428e-04\n",
            "Epoch 359/400\n",
            "14241/14241 - 21s - loss: 1.3601e-04 - val_loss: 5.2292e-04\n",
            "Epoch 360/400\n",
            "14241/14241 - 21s - loss: 1.3657e-04 - val_loss: 1.9394e-04\n",
            "Epoch 361/400\n",
            "14241/14241 - 20s - loss: 1.3731e-04 - val_loss: 0.0017\n",
            "Epoch 362/400\n",
            "14241/14241 - 21s - loss: 1.3762e-04 - val_loss: 4.1567e-04\n",
            "Epoch 363/400\n",
            "14241/14241 - 20s - loss: 1.3805e-04 - val_loss: 2.1213e-04\n",
            "Epoch 364/400\n",
            "14241/14241 - 21s - loss: 1.3631e-04 - val_loss: 2.0984e-04\n",
            "Epoch 365/400\n",
            "14241/14241 - 20s - loss: 1.3519e-04 - val_loss: 0.0017\n",
            "Epoch 366/400\n",
            "14241/14241 - 20s - loss: 1.3610e-04 - val_loss: 0.0103\n",
            "Epoch 367/400\n",
            "14241/14241 - 20s - loss: 1.3614e-04 - val_loss: 1.3985e-04\n",
            "Epoch 368/400\n",
            "14241/14241 - 20s - loss: 1.3599e-04 - val_loss: 4.7931e-04\n",
            "Epoch 369/400\n",
            "14241/14241 - 20s - loss: 1.3662e-04 - val_loss: 4.9029e-04\n",
            "Epoch 370/400\n",
            "14241/14241 - 20s - loss: 1.3808e-04 - val_loss: 2.0075e-04\n",
            "Epoch 371/400\n",
            "14241/14241 - 20s - loss: 1.3757e-04 - val_loss: 0.0056\n",
            "Epoch 372/400\n",
            "14241/14241 - 20s - loss: 1.3585e-04 - val_loss: 1.9983e-04\n",
            "Epoch 373/400\n",
            "14241/14241 - 20s - loss: 1.3709e-04 - val_loss: 5.4030e-04\n",
            "Epoch 374/400\n",
            "14241/14241 - 21s - loss: 1.3603e-04 - val_loss: 0.0016\n",
            "Epoch 375/400\n",
            "14241/14241 - 21s - loss: 1.3778e-04 - val_loss: 0.0043\n",
            "Epoch 376/400\n",
            "14241/14241 - 21s - loss: 1.3665e-04 - val_loss: 1.4445e-04\n",
            "Epoch 377/400\n",
            "14241/14241 - 21s - loss: 1.3594e-04 - val_loss: 0.0027\n",
            "Epoch 378/400\n",
            "14241/14241 - 21s - loss: 1.3547e-04 - val_loss: 0.0011\n",
            "Epoch 379/400\n",
            "14241/14241 - 21s - loss: 1.3632e-04 - val_loss: 2.3708e-04\n",
            "Epoch 380/400\n",
            "14241/14241 - 20s - loss: 1.3704e-04 - val_loss: 0.0012\n",
            "Epoch 381/400\n",
            "14241/14241 - 20s - loss: 1.3644e-04 - val_loss: 0.0013\n",
            "Epoch 382/400\n",
            "14241/14241 - 20s - loss: 1.3723e-04 - val_loss: 2.2175e-04\n",
            "Epoch 383/400\n",
            "14241/14241 - 20s - loss: 1.3750e-04 - val_loss: 0.0026\n",
            "Epoch 384/400\n",
            "14241/14241 - 20s - loss: 1.3643e-04 - val_loss: 3.8073e-04\n",
            "Epoch 385/400\n",
            "14241/14241 - 20s - loss: 1.3586e-04 - val_loss: 8.2526e-04\n",
            "Epoch 386/400\n",
            "14241/14241 - 20s - loss: 1.3520e-04 - val_loss: 4.5880e-04\n",
            "Epoch 387/400\n",
            "14241/14241 - 20s - loss: 1.3802e-04 - val_loss: 0.0019\n",
            "Epoch 388/400\n",
            "14241/14241 - 20s - loss: 1.3628e-04 - val_loss: 0.0016\n",
            "Epoch 389/400\n",
            "14241/14241 - 20s - loss: 1.3524e-04 - val_loss: 6.6135e-04\n",
            "Epoch 390/400\n",
            "14241/14241 - 20s - loss: 1.3579e-04 - val_loss: 0.0019\n",
            "Epoch 391/400\n",
            "14241/14241 - 20s - loss: 1.3604e-04 - val_loss: 2.9640e-04\n",
            "Epoch 392/400\n",
            "14241/14241 - 20s - loss: 1.3675e-04 - val_loss: 2.8343e-04\n",
            "Epoch 393/400\n",
            "14241/14241 - 20s - loss: 1.3754e-04 - val_loss: 8.1608e-04\n",
            "Epoch 394/400\n",
            "14241/14241 - 22s - loss: 1.3546e-04 - val_loss: 3.5700e-04\n",
            "Epoch 395/400\n",
            "14241/14241 - 23s - loss: 1.3499e-04 - val_loss: 0.0012\n",
            "Epoch 396/400\n",
            "14241/14241 - 22s - loss: 1.3541e-04 - val_loss: 3.0023e-04\n",
            "Epoch 397/400\n",
            "14241/14241 - 22s - loss: 1.3532e-04 - val_loss: 2.4669e-04\n",
            "Epoch 398/400\n",
            "14241/14241 - 23s - loss: 1.3610e-04 - val_loss: 4.2231e-04\n",
            "Epoch 399/400\n",
            "14241/14241 - 23s - loss: 1.3617e-04 - val_loss: 0.0015\n",
            "Epoch 400/400\n",
            "14241/14241 - 21s - loss: 1.3494e-04 - val_loss: 1.9044e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5GUIEWo_JC9F",
        "outputId": "49733a59-fe9d-4033-a7c8-a0e3d2ab2edc"
      },
      "source": [
        "# train autoencoder for classification with with compression in the bottleneck layer\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from matplotlib import pyplot\r\n",
        "# define dataset\r\n",
        "# getting data \r\n",
        "data=pd.read_csv('/content/drive/MyDrive/Classification/creditcard.csv')\r\n",
        "data.head()\r\n",
        "# splitting data into  X features  and  y target \r\n",
        "X = data.drop(['Class'], axis = 1) \r\n",
        "y = data[\"Class\"] \r\n",
        "# number of input columns\r\n",
        "n_inputs = X.shape[1]\r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "#Auto-Encoder\r\n",
        "# define encoder\r\n",
        "visible = Input(shape=(n_inputs,))\r\n",
        "# encoder level 1\r\n",
        "e = Dense(n_inputs*2)(visible)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# encoder level 2\r\n",
        "e = Dense(n_inputs)(e)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# encoder level 3\r\n",
        "#e = Dense(n_inputs)(e)\r\n",
        "#e = BatchNormalization()(e)\r\n",
        "#e = LeakyReLU()(e)\r\n",
        "# bottleneck\r\n",
        "n_bottleneck = round(float(n_inputs) / 2.0)\r\n",
        "bottleneck = Dense(n_bottleneck)(e)\r\n",
        "# define decoder, level 1\r\n",
        "d = Dense(n_inputs)(bottleneck)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# decoder level 2\r\n",
        "d = Dense(n_inputs*2)(d)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# output layer\r\n",
        "output = Dense(n_inputs, activation='linear')(d)\r\n",
        "# define autoencoder model\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "# compile autoencoder model\r\n",
        "model.compile(optimizer='adam', loss='mse')\r\n",
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder_compress.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=100, batch_size=32, verbose=2, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder_compress.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7121/7121 - 15s - loss: 0.0048 - val_loss: 4.4310e-04\n",
            "Epoch 2/100\n",
            "7121/7121 - 13s - loss: 4.7387e-04 - val_loss: 0.0013\n",
            "Epoch 3/100\n",
            "7121/7121 - 14s - loss: 3.7657e-04 - val_loss: 9.8335e-04\n",
            "Epoch 4/100\n",
            "7121/7121 - 14s - loss: 3.3527e-04 - val_loss: 8.9061e-04\n",
            "Epoch 5/100\n",
            "7121/7121 - 15s - loss: 3.1734e-04 - val_loss: 5.5858e-04\n",
            "Epoch 6/100\n",
            "7121/7121 - 16s - loss: 3.0275e-04 - val_loss: 5.0908e-04\n",
            "Epoch 7/100\n",
            "7121/7121 - 16s - loss: 2.9116e-04 - val_loss: 7.4979e-04\n",
            "Epoch 8/100\n",
            "7121/7121 - 15s - loss: 2.8269e-04 - val_loss: 9.3111e-04\n",
            "Epoch 9/100\n",
            "7121/7121 - 15s - loss: 2.7553e-04 - val_loss: 6.1881e-04\n",
            "Epoch 10/100\n",
            "7121/7121 - 15s - loss: 2.6967e-04 - val_loss: 7.6734e-04\n",
            "Epoch 11/100\n",
            "7121/7121 - 14s - loss: 2.6072e-04 - val_loss: 8.7757e-04\n",
            "Epoch 12/100\n",
            "7121/7121 - 14s - loss: 2.5238e-04 - val_loss: 4.5005e-04\n",
            "Epoch 13/100\n",
            "7121/7121 - 14s - loss: 2.4875e-04 - val_loss: 3.1694e-04\n",
            "Epoch 14/100\n",
            "7121/7121 - 14s - loss: 2.4207e-04 - val_loss: 7.0241e-04\n",
            "Epoch 15/100\n",
            "7121/7121 - 14s - loss: 2.3830e-04 - val_loss: 4.6848e-04\n",
            "Epoch 16/100\n",
            "7121/7121 - 14s - loss: 2.3337e-04 - val_loss: 6.2847e-04\n",
            "Epoch 17/100\n",
            "7121/7121 - 14s - loss: 2.2834e-04 - val_loss: 2.7013e-04\n",
            "Epoch 18/100\n",
            "7121/7121 - 14s - loss: 2.2491e-04 - val_loss: 2.8735e-04\n",
            "Epoch 19/100\n",
            "7121/7121 - 14s - loss: 2.2154e-04 - val_loss: 2.2455e-04\n",
            "Epoch 20/100\n",
            "7121/7121 - 14s - loss: 2.1862e-04 - val_loss: 5.6357e-04\n",
            "Epoch 21/100\n",
            "7121/7121 - 14s - loss: 2.1487e-04 - val_loss: 5.2968e-04\n",
            "Epoch 22/100\n",
            "7121/7121 - 14s - loss: 2.1233e-04 - val_loss: 5.2964e-04\n",
            "Epoch 23/100\n",
            "7121/7121 - 14s - loss: 2.0568e-04 - val_loss: 2.0487e-04\n",
            "Epoch 24/100\n",
            "7121/7121 - 14s - loss: 2.0350e-04 - val_loss: 8.3734e-04\n",
            "Epoch 25/100\n",
            "7121/7121 - 14s - loss: 1.9995e-04 - val_loss: 1.9706e-04\n",
            "Epoch 26/100\n",
            "7121/7121 - 14s - loss: 1.9786e-04 - val_loss: 1.4429e-04\n",
            "Epoch 27/100\n",
            "7121/7121 - 14s - loss: 1.9518e-04 - val_loss: 1.7925e-04\n",
            "Epoch 28/100\n",
            "7121/7121 - 15s - loss: 1.9229e-04 - val_loss: 3.5142e-04\n",
            "Epoch 29/100\n",
            "7121/7121 - 14s - loss: 1.8788e-04 - val_loss: 1.7682e-04\n",
            "Epoch 30/100\n",
            "7121/7121 - 14s - loss: 1.8528e-04 - val_loss: 3.5289e-04\n",
            "Epoch 31/100\n",
            "7121/7121 - 14s - loss: 1.8335e-04 - val_loss: 0.0011\n",
            "Epoch 32/100\n",
            "7121/7121 - 14s - loss: 1.8151e-04 - val_loss: 2.8770e-04\n",
            "Epoch 33/100\n",
            "7121/7121 - 14s - loss: 1.7879e-04 - val_loss: 2.2222e-04\n",
            "Epoch 34/100\n",
            "7121/7121 - 14s - loss: 1.7595e-04 - val_loss: 9.9686e-04\n",
            "Epoch 35/100\n",
            "7121/7121 - 14s - loss: 1.7332e-04 - val_loss: 4.5072e-04\n",
            "Epoch 36/100\n",
            "7121/7121 - 14s - loss: 1.7028e-04 - val_loss: 5.0682e-04\n",
            "Epoch 37/100\n",
            "7121/7121 - 14s - loss: 1.6818e-04 - val_loss: 6.0607e-04\n",
            "Epoch 38/100\n",
            "7121/7121 - 14s - loss: 1.6638e-04 - val_loss: 1.4332e-04\n",
            "Epoch 39/100\n",
            "7121/7121 - 13s - loss: 1.6511e-04 - val_loss: 7.6781e-05\n",
            "Epoch 40/100\n",
            "7121/7121 - 14s - loss: 1.6304e-04 - val_loss: 2.3434e-04\n",
            "Epoch 41/100\n",
            "7121/7121 - 14s - loss: 1.6108e-04 - val_loss: 1.6716e-04\n",
            "Epoch 42/100\n",
            "7121/7121 - 14s - loss: 1.5932e-04 - val_loss: 4.2968e-04\n",
            "Epoch 43/100\n",
            "7121/7121 - 14s - loss: 1.5820e-04 - val_loss: 3.1455e-04\n",
            "Epoch 44/100\n",
            "7121/7121 - 14s - loss: 1.5537e-04 - val_loss: 1.8467e-04\n",
            "Epoch 45/100\n",
            "7121/7121 - 14s - loss: 1.5409e-04 - val_loss: 2.8693e-04\n",
            "Epoch 46/100\n",
            "7121/7121 - 14s - loss: 1.5276e-04 - val_loss: 1.9435e-04\n",
            "Epoch 47/100\n",
            "7121/7121 - 14s - loss: 1.5116e-04 - val_loss: 1.4578e-04\n",
            "Epoch 48/100\n",
            "7121/7121 - 14s - loss: 1.4968e-04 - val_loss: 2.6928e-04\n",
            "Epoch 49/100\n",
            "7121/7121 - 14s - loss: 1.4903e-04 - val_loss: 4.0941e-04\n",
            "Epoch 50/100\n",
            "7121/7121 - 14s - loss: 1.4837e-04 - val_loss: 1.4835e-04\n",
            "Epoch 51/100\n",
            "7121/7121 - 14s - loss: 1.4760e-04 - val_loss: 2.9341e-04\n",
            "Epoch 52/100\n",
            "7121/7121 - 14s - loss: 1.4607e-04 - val_loss: 4.2443e-04\n",
            "Epoch 53/100\n",
            "7121/7121 - 15s - loss: 1.4634e-04 - val_loss: 1.3673e-04\n",
            "Epoch 54/100\n",
            "7121/7121 - 14s - loss: 1.4400e-04 - val_loss: 2.7479e-04\n",
            "Epoch 55/100\n",
            "7121/7121 - 14s - loss: 1.4279e-04 - val_loss: 1.9710e-04\n",
            "Epoch 56/100\n",
            "7121/7121 - 14s - loss: 1.4118e-04 - val_loss: 3.3801e-04\n",
            "Epoch 57/100\n",
            "7121/7121 - 14s - loss: 1.4128e-04 - val_loss: 3.4868e-04\n",
            "Epoch 58/100\n",
            "7121/7121 - 15s - loss: 1.4047e-04 - val_loss: 2.2204e-04\n",
            "Epoch 59/100\n",
            "7121/7121 - 15s - loss: 1.3974e-04 - val_loss: 0.0012\n",
            "Epoch 60/100\n",
            "7121/7121 - 14s - loss: 1.3805e-04 - val_loss: 3.7949e-04\n",
            "Epoch 61/100\n",
            "7121/7121 - 14s - loss: 1.3782e-04 - val_loss: 1.2294e-04\n",
            "Epoch 62/100\n",
            "7121/7121 - 15s - loss: 1.3638e-04 - val_loss: 1.8458e-04\n",
            "Epoch 63/100\n",
            "7121/7121 - 14s - loss: 1.3623e-04 - val_loss: 0.0041\n",
            "Epoch 64/100\n",
            "7121/7121 - 14s - loss: 1.3409e-04 - val_loss: 2.6211e-04\n",
            "Epoch 65/100\n",
            "7121/7121 - 14s - loss: 1.3566e-04 - val_loss: 1.3122e-04\n",
            "Epoch 66/100\n",
            "7121/7121 - 15s - loss: 1.3391e-04 - val_loss: 1.0773e-04\n",
            "Epoch 67/100\n",
            "7121/7121 - 15s - loss: 1.3348e-04 - val_loss: 7.7197e-05\n",
            "Epoch 68/100\n",
            "7121/7121 - 15s - loss: 1.3357e-04 - val_loss: 1.6017e-04\n",
            "Epoch 69/100\n",
            "7121/7121 - 14s - loss: 1.3208e-04 - val_loss: 1.5608e-04\n",
            "Epoch 70/100\n",
            "7121/7121 - 15s - loss: 1.3222e-04 - val_loss: 1.0171e-04\n",
            "Epoch 71/100\n",
            "7121/7121 - 15s - loss: 1.3210e-04 - val_loss: 5.0001e-04\n",
            "Epoch 72/100\n",
            "7121/7121 - 16s - loss: 1.3122e-04 - val_loss: 1.1416e-04\n",
            "Epoch 73/100\n",
            "7121/7121 - 15s - loss: 1.3101e-04 - val_loss: 1.1494e-04\n",
            "Epoch 74/100\n",
            "7121/7121 - 14s - loss: 1.3012e-04 - val_loss: 1.4387e-04\n",
            "Epoch 75/100\n",
            "7121/7121 - 14s - loss: 1.2985e-04 - val_loss: 3.1493e-04\n",
            "Epoch 76/100\n",
            "7121/7121 - 14s - loss: 1.2897e-04 - val_loss: 1.2344e-04\n",
            "Epoch 77/100\n",
            "7121/7121 - 14s - loss: 1.2962e-04 - val_loss: 3.5615e-04\n",
            "Epoch 78/100\n",
            "7121/7121 - 14s - loss: 1.2833e-04 - val_loss: 1.1655e-04\n",
            "Epoch 79/100\n",
            "7121/7121 - 14s - loss: 1.2865e-04 - val_loss: 1.9761e-04\n",
            "Epoch 80/100\n",
            "7121/7121 - 14s - loss: 1.2737e-04 - val_loss: 1.7915e-04\n",
            "Epoch 81/100\n",
            "7121/7121 - 14s - loss: 1.2721e-04 - val_loss: 2.9226e-04\n",
            "Epoch 82/100\n",
            "7121/7121 - 15s - loss: 1.2746e-04 - val_loss: 3.8460e-04\n",
            "Epoch 83/100\n",
            "7121/7121 - 15s - loss: 1.2645e-04 - val_loss: 1.9729e-04\n",
            "Epoch 84/100\n",
            "7121/7121 - 13s - loss: 1.2585e-04 - val_loss: 0.0030\n",
            "Epoch 85/100\n",
            "7121/7121 - 14s - loss: 1.2549e-04 - val_loss: 9.8977e-04\n",
            "Epoch 86/100\n",
            "7121/7121 - 13s - loss: 1.2474e-04 - val_loss: 9.6331e-05\n",
            "Epoch 87/100\n",
            "7121/7121 - 13s - loss: 1.2435e-04 - val_loss: 6.3419e-05\n",
            "Epoch 88/100\n",
            "7121/7121 - 14s - loss: 1.2475e-04 - val_loss: 3.4721e-04\n",
            "Epoch 89/100\n",
            "7121/7121 - 14s - loss: 1.2470e-04 - val_loss: 3.2393e-04\n",
            "Epoch 90/100\n",
            "7121/7121 - 13s - loss: 1.2395e-04 - val_loss: 7.9554e-05\n",
            "Epoch 91/100\n",
            "7121/7121 - 14s - loss: 1.2333e-04 - val_loss: 1.8713e-04\n",
            "Epoch 92/100\n",
            "7121/7121 - 13s - loss: 1.2291e-04 - val_loss: 1.0911e-04\n",
            "Epoch 93/100\n",
            "7121/7121 - 14s - loss: 1.2338e-04 - val_loss: 4.7995e-04\n",
            "Epoch 94/100\n",
            "7121/7121 - 14s - loss: 1.2281e-04 - val_loss: 1.2958e-04\n",
            "Epoch 95/100\n",
            "7121/7121 - 14s - loss: 1.2211e-04 - val_loss: 1.8902e-04\n",
            "Epoch 96/100\n",
            "7121/7121 - 14s - loss: 1.2215e-04 - val_loss: 8.0390e-05\n",
            "Epoch 97/100\n",
            "7121/7121 - 13s - loss: 1.2187e-04 - val_loss: 3.9857e-04\n",
            "Epoch 98/100\n",
            "7121/7121 - 14s - loss: 1.2138e-04 - val_loss: 2.4374e-04\n",
            "Epoch 99/100\n",
            "7121/7121 - 13s - loss: 1.2120e-04 - val_loss: 1.6843e-04\n",
            "Epoch 100/100\n",
            "7121/7121 - 14s - loss: 1.2201e-04 - val_loss: 1.0719e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "XdgYZ4FPFERy",
        "outputId": "fe4ee812-19ae-4b78-901c-2e4787550a3b"
      },
      "source": [
        "# evaluate logistic regression on encoded input\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "# define dataset\r\n",
        "#getting data \r\n",
        "data=pd.read_csv('/content/drive/MyDrive/Classification/creditcard.csv')\r\n",
        "data.head()\r\n",
        "# splitting data into  X features  and  y target \r\n",
        "X = data.drop(['Class'], axis = 1) \r\n",
        "y = data[\"Class\"] \r\n",
        "# split into train test sets\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\r\n",
        "# scale data\r\n",
        "t = MinMaxScaler()\r\n",
        "t.fit(X_train)\r\n",
        "X_train = t.transform(X_train)\r\n",
        "X_test = t.transform(X_test)\r\n",
        "# load the model from file\r\n",
        "encoder = load_model('encoder.h5')\r\n",
        "# encode the train data\r\n",
        "X_train_encode = encoder.predict(X_train)\r\n",
        "# encode the test data\r\n",
        "X_test_encode = encoder.predict(X_test)\r\n",
        "# define the model\r\n",
        "model = LogisticRegression()\r\n",
        "# fit the model on the training set\r\n",
        "model.fit(X_train_encode, y_train)\r\n",
        "# make predictions on the test set\r\n",
        "yhat = model.predict(X_test_encode)\r\n",
        "# calculate classification accuracy\r\n",
        "acc = accuracy_score(y_test, yhat)\r\n",
        "print(acc)\r\n",
        "\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "0.9991573329588147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4433ce80db02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Score :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing Score :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 287\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
            "\u001b[0;31mValueError\u001b[0m: X has 30 features per sample; expecting 15"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asvuq1FmvXVG",
        "outputId": "2bc25c20-9e70-4243-f43a-3794d87fb90d"
      },
      "source": [
        "#DEFINE A HELPER FUNCTION TO SHOW EVALUATION METRICS \r\n",
        "def evaluate(y_test,preds):\r\n",
        "    print('****EVALUATIONS METRICS****')\r\n",
        "    accuracy = round(accuracy_score(y_test, preds),2)\r\n",
        "    print(\"Accuracy == {}\".format(accuracy)) \r\n",
        "    #precision\r\n",
        "    precision = round(precision_score(y_test, preds),2)\r\n",
        "    print(\"Precision == {}\".format(precision)) \r\n",
        "    #recall\r\n",
        "    recall = round(recall_score(y_test, preds),2)\r\n",
        "    print(\"Recall == {}\".format(recall)) \r\n",
        "    #F1 score\r\n",
        "    f1 = round(f1_score(y_test, yhat),2)\r\n",
        "    print(\"F1-Score == {}\".format(f1)) \r\n",
        "\r\n",
        "# Show results on Random Forest Classifier \r\n",
        "evaluate(y_test,yhat) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****EVALUATIONS METRICS****\n",
            "Accuracy == 1.0\n",
            "Precision == 0.84\n",
            "Recall == 0.55\n",
            "F1-Score == 0.67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "oxdS0WTOwHUt",
        "outputId": "73402ba3-923f-4ac4-cee1-bb55340e9613"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****EVALUATIONS METRICS****\n",
            "Accuracy == 1.0\n",
            "Precision == 0.84\n",
            "Recall == 0.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1c1229e74b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show results on Random Forest Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-a11babdc7970>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(y_test, preds)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall == {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#F1 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrfc_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F1-Score == {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rfc_preds' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "wrUCLjIYwfdE",
        "outputId": "a6c7f6b4-c8d7-466e-e8a2-e2edb034a8d8"
      },
      "source": [
        "# printing the confusion matrix \r\n",
        "conf_matrix = confusion_matrix(y_test, yhat) \r\n",
        "plt.figure(figsize =(8, 8)) \r\n",
        "sb.heatmap(conf_matrix, xticklabels =['Valid', 'Fraud'], \r\n",
        "           yticklabels = ['Valid', 'Fraud'], annot = True, fmt =\"d\")\r\n",
        "plt.title(\"Confusion matrix\") \r\n",
        "plt.ylabel('True Class') \r\n",
        "plt.xlabel('Predicted Class') \r\n",
        "plt.show() "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "7Ii5qHLQxJIu",
        "outputId": "6dee40f4-f199-4048-f005-df02c7df8e9d"
      },
      "source": [
        "#let's shuffle the dataset before getting into undersampling \r\n",
        "data=data.sample(frac=1)\r\n",
        "#separate fraud and non fraud transactions \r\n",
        "fraud=data[data.Class==1]\r\n",
        "nonfraud=data[data.Class==0][:500]\r\n",
        "# create a balanced datafrme of fraud and non fraud transactions and worn on it \r\n",
        "balanced_df = pd.concat([fraud, nonfraud])\r\n",
        "# Shuffle dataframe rows\r\n",
        "balanced_df= balanced_df.sample(frac=1, random_state=101)\r\n",
        "#show \r\n",
        "balanced_df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6717</th>\n",
              "      <td>8408.0</td>\n",
              "      <td>-1.813280</td>\n",
              "      <td>4.917851</td>\n",
              "      <td>-5.926130</td>\n",
              "      <td>5.701500</td>\n",
              "      <td>1.204393</td>\n",
              "      <td>-3.035138</td>\n",
              "      <td>-1.713402</td>\n",
              "      <td>0.561257</td>\n",
              "      <td>-3.796354</td>\n",
              "      <td>-7.454841</td>\n",
              "      <td>7.388055</td>\n",
              "      <td>-10.475229</td>\n",
              "      <td>-0.379315</td>\n",
              "      <td>-11.736729</td>\n",
              "      <td>-2.086989</td>\n",
              "      <td>-2.442354</td>\n",
              "      <td>-3.535524</td>\n",
              "      <td>0.130360</td>\n",
              "      <td>-2.071450</td>\n",
              "      <td>0.576656</td>\n",
              "      <td>0.615642</td>\n",
              "      <td>-0.406427</td>\n",
              "      <td>-0.737018</td>\n",
              "      <td>-0.279642</td>\n",
              "      <td>1.106766</td>\n",
              "      <td>0.323885</td>\n",
              "      <td>0.894767</td>\n",
              "      <td>0.569519</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9861</th>\n",
              "      <td>14532.0</td>\n",
              "      <td>1.183594</td>\n",
              "      <td>-0.082875</td>\n",
              "      <td>0.736538</td>\n",
              "      <td>0.081360</td>\n",
              "      <td>-0.401886</td>\n",
              "      <td>0.148805</td>\n",
              "      <td>-0.601341</td>\n",
              "      <td>0.084268</td>\n",
              "      <td>1.446284</td>\n",
              "      <td>-0.404412</td>\n",
              "      <td>2.324723</td>\n",
              "      <td>-1.527121</td>\n",
              "      <td>2.069047</td>\n",
              "      <td>1.615536</td>\n",
              "      <td>0.119014</td>\n",
              "      <td>0.470962</td>\n",
              "      <td>0.184618</td>\n",
              "      <td>0.268117</td>\n",
              "      <td>-0.351163</td>\n",
              "      <td>-0.070431</td>\n",
              "      <td>-0.004884</td>\n",
              "      <td>0.262987</td>\n",
              "      <td>-0.042969</td>\n",
              "      <td>-0.282364</td>\n",
              "      <td>0.158542</td>\n",
              "      <td>1.062763</td>\n",
              "      <td>-0.075016</td>\n",
              "      <td>-0.010410</td>\n",
              "      <td>15.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24185</th>\n",
              "      <td>33106.0</td>\n",
              "      <td>-0.484275</td>\n",
              "      <td>-0.061692</td>\n",
              "      <td>1.073505</td>\n",
              "      <td>-2.025112</td>\n",
              "      <td>0.302511</td>\n",
              "      <td>-0.174966</td>\n",
              "      <td>0.451924</td>\n",
              "      <td>-0.085669</td>\n",
              "      <td>-1.246568</td>\n",
              "      <td>0.610028</td>\n",
              "      <td>-0.090807</td>\n",
              "      <td>-0.577508</td>\n",
              "      <td>-0.484727</td>\n",
              "      <td>0.046285</td>\n",
              "      <td>-0.269584</td>\n",
              "      <td>-0.636327</td>\n",
              "      <td>-1.000255</td>\n",
              "      <td>1.748315</td>\n",
              "      <td>-0.458264</td>\n",
              "      <td>-0.177287</td>\n",
              "      <td>-0.589349</td>\n",
              "      <td>-1.189862</td>\n",
              "      <td>-0.034892</td>\n",
              "      <td>-0.871931</td>\n",
              "      <td>-0.360283</td>\n",
              "      <td>0.683183</td>\n",
              "      <td>0.087477</td>\n",
              "      <td>-0.060562</td>\n",
              "      <td>36.94</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220265</th>\n",
              "      <td>142094.0</td>\n",
              "      <td>0.340234</td>\n",
              "      <td>1.152763</td>\n",
              "      <td>-1.175821</td>\n",
              "      <td>0.100135</td>\n",
              "      <td>-0.300351</td>\n",
              "      <td>-0.229592</td>\n",
              "      <td>-1.852650</td>\n",
              "      <td>-5.557464</td>\n",
              "      <td>-0.240797</td>\n",
              "      <td>-1.291457</td>\n",
              "      <td>-0.857302</td>\n",
              "      <td>0.807808</td>\n",
              "      <td>-0.180211</td>\n",
              "      <td>1.246466</td>\n",
              "      <td>0.525811</td>\n",
              "      <td>0.140648</td>\n",
              "      <td>-0.266283</td>\n",
              "      <td>0.044085</td>\n",
              "      <td>-0.642384</td>\n",
              "      <td>1.092370</td>\n",
              "      <td>-2.258351</td>\n",
              "      <td>1.656770</td>\n",
              "      <td>0.200159</td>\n",
              "      <td>0.057004</td>\n",
              "      <td>0.608551</td>\n",
              "      <td>-0.076586</td>\n",
              "      <td>-0.036854</td>\n",
              "      <td>0.130159</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176049</th>\n",
              "      <td>122608.0</td>\n",
              "      <td>-2.003460</td>\n",
              "      <td>-7.159042</td>\n",
              "      <td>-4.050976</td>\n",
              "      <td>1.309580</td>\n",
              "      <td>-2.058102</td>\n",
              "      <td>-0.098621</td>\n",
              "      <td>2.880083</td>\n",
              "      <td>-0.727484</td>\n",
              "      <td>1.460381</td>\n",
              "      <td>-1.531608</td>\n",
              "      <td>-1.394328</td>\n",
              "      <td>-0.220719</td>\n",
              "      <td>-1.530990</td>\n",
              "      <td>1.075248</td>\n",
              "      <td>0.388383</td>\n",
              "      <td>-0.660655</td>\n",
              "      <td>0.093321</td>\n",
              "      <td>0.335742</td>\n",
              "      <td>0.057551</td>\n",
              "      <td>3.973217</td>\n",
              "      <td>1.244287</td>\n",
              "      <td>-1.015232</td>\n",
              "      <td>-1.800985</td>\n",
              "      <td>0.657586</td>\n",
              "      <td>-0.435617</td>\n",
              "      <td>-0.894509</td>\n",
              "      <td>-0.397557</td>\n",
              "      <td>0.314262</td>\n",
              "      <td>2125.87</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "6717      8408.0 -1.813280  4.917851 -5.926130  5.701500  1.204393 -3.035138   \n",
              "9861     14532.0  1.183594 -0.082875  0.736538  0.081360 -0.401886  0.148805   \n",
              "24185    33106.0 -0.484275 -0.061692  1.073505 -2.025112  0.302511 -0.174966   \n",
              "220265  142094.0  0.340234  1.152763 -1.175821  0.100135 -0.300351 -0.229592   \n",
              "176049  122608.0 -2.003460 -7.159042 -4.050976  1.309580 -2.058102 -0.098621   \n",
              "\n",
              "              V7        V8        V9       V10       V11        V12       V13  \\\n",
              "6717   -1.713402  0.561257 -3.796354 -7.454841  7.388055 -10.475229 -0.379315   \n",
              "9861   -0.601341  0.084268  1.446284 -0.404412  2.324723  -1.527121  2.069047   \n",
              "24185   0.451924 -0.085669 -1.246568  0.610028 -0.090807  -0.577508 -0.484727   \n",
              "220265 -1.852650 -5.557464 -0.240797 -1.291457 -0.857302   0.807808 -0.180211   \n",
              "176049  2.880083 -0.727484  1.460381 -1.531608 -1.394328  -0.220719 -1.530990   \n",
              "\n",
              "              V14       V15       V16       V17       V18       V19       V20  \\\n",
              "6717   -11.736729 -2.086989 -2.442354 -3.535524  0.130360 -2.071450  0.576656   \n",
              "9861     1.615536  0.119014  0.470962  0.184618  0.268117 -0.351163 -0.070431   \n",
              "24185    0.046285 -0.269584 -0.636327 -1.000255  1.748315 -0.458264 -0.177287   \n",
              "220265   1.246466  0.525811  0.140648 -0.266283  0.044085 -0.642384  1.092370   \n",
              "176049   1.075248  0.388383 -0.660655  0.093321  0.335742  0.057551  3.973217   \n",
              "\n",
              "             V21       V22       V23       V24       V25       V26       V27  \\\n",
              "6717    0.615642 -0.406427 -0.737018 -0.279642  1.106766  0.323885  0.894767   \n",
              "9861   -0.004884  0.262987 -0.042969 -0.282364  0.158542  1.062763 -0.075016   \n",
              "24185  -0.589349 -1.189862 -0.034892 -0.871931 -0.360283  0.683183  0.087477   \n",
              "220265 -2.258351  1.656770  0.200159  0.057004  0.608551 -0.076586 -0.036854   \n",
              "176049  1.244287 -1.015232 -1.800985  0.657586 -0.435617 -0.894509 -0.397557   \n",
              "\n",
              "             V28   Amount  Class  \n",
              "6717    0.569519     1.00      1  \n",
              "9861   -0.010410    15.95      0  \n",
              "24185  -0.060562    36.94      0  \n",
              "220265  0.130159     1.00      0  \n",
              "176049  0.314262  2125.87      1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icNB4g6Ix9o2",
        "outputId": "372ce627-5edc-498a-b721-441bc47d7310"
      },
      "source": [
        "print(\"Before Undersampling :\\n\",data.Class.value_counts())\r\n",
        "print('________-----________')\r\n",
        "print(\"After Undersampling :\\n\",balanced_df.Class.value_counts())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Undersampling :\n",
            " 0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n",
            "________-----________\n",
            "After Undersampling :\n",
            " 0    500\n",
            "1    492\n",
            "Name: Class, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "9TXCRuUGyBaO",
        "outputId": "a3a9e21a-5b3a-41fe-8bdd-cb48ebdaa086"
      },
      "source": [
        "sb.countplot(data=balanced_df,x='Class')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f178feede48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9MN7gUEyEY1",
        "outputId": "b34e6808-dcde-47fe-a05d-1a011bb499bf"
      },
      "source": [
        "balanced_df.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(992, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztI789RRyIfG",
        "outputId": "233fbfb5-13f5-4a6b-d123-fbe9371e2ed9"
      },
      "source": [
        "df=balanced_df.copy()\r\n",
        "# dividing the X  and the Y  from the balanced dataset \r\n",
        "X_balanced = df.drop(['Class'], axis = 1) \r\n",
        "y_balanced = df[\"Class\"] \r\n",
        "print('X_balanced: Features || y_balanced:Class Labels: \\n')\r\n",
        "print(X_balanced.shape,y_balanced.shape) \r\n",
        "# getting just the values for the sake of processing  \r\n",
        "# (its a numpy array with no columns) \r\n",
        "X_balanced = X_balanced.values \r\n",
        "y_balanced = y_balanced.values \r\n",
        "# Split the data into training and testing sets \r\n",
        "X_train, X_test, y_train, y_test = train_test_split( X_balanced,y_balanced , test_size = 0.2, random_state = 101) \r\n",
        "print('\\n')\r\n",
        "print('After Splitting : \\n')\r\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_balanced: Features || y_balanced:Class Labels: \n",
            "\n",
            "(992, 30) (992,)\n",
            "\n",
            "\n",
            "After Splitting : \n",
            "\n",
            "(793, 30) (199, 30) (793,) (199,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PuPSwjByNrF",
        "outputId": "b05f31b2-87dd-455f-e87d-b7676414aaad"
      },
      "source": [
        "# Random Forest Classifier (RANDOM FOREST) \r\n",
        "rfc = RandomForestClassifier()\r\n",
        "# Decison Tree Classifier \r\n",
        "dt=DecisionTreeClassifier()\r\n",
        "# Logistic Regression Classifier\r\n",
        "lr=LogisticRegression()\r\n",
        "#put those alorithms into a dictionnary \r\n",
        "models={'Random Forest Classifier': rfc,'Decision Tree':dt,'Logistic Regression':lr}\r\n",
        "predictions={}\r\n",
        "for name,model in models.items():\r\n",
        "    print('***********')\r\n",
        "    print(f'TRAINING {name} Model ')\r\n",
        "    model.fit(X_train,y_train)\r\n",
        "    print('FINISHED TRAINING \\n')\r\n",
        "    print(f'TRAIN SCORE : {model.score(X_train,y_train)}\\n')\r\n",
        "    print(f'TEST SCORE : {model.score(X_test,y_test)}\\n')\r\n",
        "    predictions[name] = model.predict(X_test) \r\n",
        "    print(f'DONE WITH {name} MODEL')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********\n",
            "TRAINING Random Forest Classifier Model \n",
            "FINISHED TRAINING \n",
            "\n",
            "TRAIN SCORE : 1.0\n",
            "\n",
            "TEST SCORE : 0.964824120603015\n",
            "\n",
            "DONE WITH Random Forest Classifier MODEL\n",
            "***********\n",
            "TRAINING Decision Tree Model \n",
            "FINISHED TRAINING \n",
            "\n",
            "TRAIN SCORE : 1.0\n",
            "\n",
            "TEST SCORE : 0.9095477386934674\n",
            "\n",
            "DONE WITH Decision Tree MODEL\n",
            "***********\n",
            "TRAINING Logistic Regression Model \n",
            "FINISHED TRAINING \n",
            "\n",
            "TRAIN SCORE : 0.9394703656998739\n",
            "\n",
            "TEST SCORE : 0.9698492462311558\n",
            "\n",
            "DONE WITH Logistic Regression MODEL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dc596dc0a52549f9b2c4bac243d81cf1",
            "5dc58762d31c41c58f4ef6e2744afcfa",
            "79ca62ee9588400b95d07fbb985929ed",
            "633b199a0a674e5492b7ed62d8a11546",
            "4c40f7baad914941bfa9db5ad9914c22",
            "ff733433cd964bf2980eed59a8ee7fa5"
          ]
        },
        "id": "Lkbc5GibyYDV",
        "outputId": "9b886856-eaf8-441d-8744-6a24075fc9f8"
      },
      "source": [
        "# Setup the dataset and preprocess \r\n",
        "pycaret_clf=setup(data=balanced_df,target='Class',train_size=0.8)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>4604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>0: 0, 1: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(992, 31)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(793, 30)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(199, 30)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>70ad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>constant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id              4604\n",
              "1                                   Target             Class\n",
              "2                              Target Type            Binary\n",
              "3                            Label Encoded        0: 0, 1: 1\n",
              "4                            Original Data         (992, 31)\n",
              "5                           Missing Values             False\n",
              "6                         Numeric Features                30\n",
              "7                     Categorical Features                 0\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set         (793, 30)\n",
              "12                    Transformed Test Set         (199, 30)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment             False\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              70ad\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer              mean\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer          constant\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize             False\n",
              "30                        Normalize Method              None\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44                              Clustering             False\n",
              "45                    Clustering Iteration              None\n",
              "46                     Polynomial Features             False\n",
              "47                       Polynomial Degree              None\n",
              "48                    Trignometry Features             False\n",
              "49                    Polynomial Threshold              None\n",
              "50                          Group Features             False\n",
              "51                       Feature Selection             False\n",
              "52            Features Selection Threshold              None\n",
              "53                     Feature Interaction             False\n",
              "54                           Feature Ratio             False\n",
              "55                   Interaction Threshold              None\n",
              "56                           Fix Imbalance             False\n",
              "57                    Fix Imbalance Method             SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607,
          "referenced_widgets": [
            "b8f403f33a884b8caab945988e433994",
            "047ba611ab2e4b1b97a0e6e9ef8ebcca",
            "e3d3023c2d514a9fa2fb5ffd01214fa5"
          ]
        },
        "id": "TGKx4H6OyliW",
        "outputId": "c9854ee8-015d-4311-b12c-249f0a316eb3"
      },
      "source": [
        "#let's compare models  \r\n",
        "compare_models()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.9483</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9349</td>\n",
              "      <td>0.9633</td>\n",
              "      <td>0.9479</td>\n",
              "      <td>0.8967</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>0.295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>xgboost</th>\n",
              "      <td>Extreme Gradient Boosting</td>\n",
              "      <td>0.9471</td>\n",
              "      <td>0.9793</td>\n",
              "      <td>0.9298</td>\n",
              "      <td>0.9646</td>\n",
              "      <td>0.9462</td>\n",
              "      <td>0.8942</td>\n",
              "      <td>0.8961</td>\n",
              "      <td>1.339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>catboost</th>\n",
              "      <td>CatBoost Classifier</td>\n",
              "      <td>0.9459</td>\n",
              "      <td>0.9844</td>\n",
              "      <td>0.9149</td>\n",
              "      <td>0.9762</td>\n",
              "      <td>0.9438</td>\n",
              "      <td>0.8918</td>\n",
              "      <td>0.8947</td>\n",
              "      <td>9.314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.9395</td>\n",
              "      <td>0.9797</td>\n",
              "      <td>0.9198</td>\n",
              "      <td>0.9597</td>\n",
              "      <td>0.9384</td>\n",
              "      <td>0.8791</td>\n",
              "      <td>0.8815</td>\n",
              "      <td>0.529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.9370</td>\n",
              "      <td>0.9824</td>\n",
              "      <td>0.8948</td>\n",
              "      <td>0.9786</td>\n",
              "      <td>0.9339</td>\n",
              "      <td>0.8741</td>\n",
              "      <td>0.8787</td>\n",
              "      <td>0.465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.9357</td>\n",
              "      <td>0.9741</td>\n",
              "      <td>0.9074</td>\n",
              "      <td>0.9638</td>\n",
              "      <td>0.9336</td>\n",
              "      <td>0.8715</td>\n",
              "      <td>0.8748</td>\n",
              "      <td>0.498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.9332</td>\n",
              "      <td>0.9792</td>\n",
              "      <td>0.9048</td>\n",
              "      <td>0.9617</td>\n",
              "      <td>0.9312</td>\n",
              "      <td>0.8665</td>\n",
              "      <td>0.8700</td>\n",
              "      <td>0.560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.9332</td>\n",
              "      <td>0.9748</td>\n",
              "      <td>0.9148</td>\n",
              "      <td>0.9519</td>\n",
              "      <td>0.9322</td>\n",
              "      <td>0.8665</td>\n",
              "      <td>0.8685</td>\n",
              "      <td>0.197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.9180</td>\n",
              "      <td>0.9635</td>\n",
              "      <td>0.8894</td>\n",
              "      <td>0.9443</td>\n",
              "      <td>0.9157</td>\n",
              "      <td>0.8360</td>\n",
              "      <td>0.8379</td>\n",
              "      <td>0.025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.9142</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8367</td>\n",
              "      <td>0.9909</td>\n",
              "      <td>0.9067</td>\n",
              "      <td>0.8285</td>\n",
              "      <td>0.8394</td>\n",
              "      <td>0.023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.9142</td>\n",
              "      <td>0.9687</td>\n",
              "      <td>0.8367</td>\n",
              "      <td>0.9909</td>\n",
              "      <td>0.9067</td>\n",
              "      <td>0.8285</td>\n",
              "      <td>0.8394</td>\n",
              "      <td>0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.9106</td>\n",
              "      <td>0.9106</td>\n",
              "      <td>0.9096</td>\n",
              "      <td>0.9137</td>\n",
              "      <td>0.9106</td>\n",
              "      <td>0.8212</td>\n",
              "      <td>0.8231</td>\n",
              "      <td>0.030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8462</td>\n",
              "      <td>0.9682</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.9839</td>\n",
              "      <td>0.8202</td>\n",
              "      <td>0.6926</td>\n",
              "      <td>0.7234</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.6496</td>\n",
              "      <td>0.6979</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.6619</td>\n",
              "      <td>0.6404</td>\n",
              "      <td>0.2992</td>\n",
              "      <td>0.3026</td>\n",
              "      <td>0.122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.5044</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5200</td>\n",
              "      <td>0.3128</td>\n",
              "      <td>0.3646</td>\n",
              "      <td>0.0071</td>\n",
              "      <td>0.0097</td>\n",
              "      <td>0.024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "lightgbm  Light Gradient Boosting Machine    0.9483  0.9833  0.9349  0.9633   \n",
              "xgboost         Extreme Gradient Boosting    0.9471  0.9793  0.9298  0.9646   \n",
              "catboost              CatBoost Classifier    0.9459  0.9844  0.9149  0.9762   \n",
              "gbc          Gradient Boosting Classifier    0.9395  0.9797  0.9198  0.9597   \n",
              "et                 Extra Trees Classifier    0.9370  0.9824  0.8948  0.9786   \n",
              "lr                    Logistic Regression    0.9357  0.9741  0.9074  0.9638   \n",
              "rf               Random Forest Classifier    0.9332  0.9792  0.9048  0.9617   \n",
              "ada                  Ada Boost Classifier    0.9332  0.9748  0.9148  0.9519   \n",
              "qda       Quadratic Discriminant Analysis    0.9180  0.9635  0.8894  0.9443   \n",
              "ridge                    Ridge Classifier    0.9142  0.0000  0.8367  0.9909   \n",
              "lda          Linear Discriminant Analysis    0.9142  0.9687  0.8367  0.9909   \n",
              "dt               Decision Tree Classifier    0.9106  0.9106  0.9096  0.9137   \n",
              "nb                            Naive Bayes    0.8462  0.9682  0.7060  0.9839   \n",
              "knn                K Neighbors Classifier    0.6496  0.6979  0.6260  0.6619   \n",
              "svm                   SVM - Linear Kernel    0.5044  0.0000  0.5200  0.3128   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "lightgbm  0.9479  0.8967  0.8988     0.295  \n",
              "xgboost   0.9462  0.8942  0.8961     1.339  \n",
              "catboost  0.9438  0.8918  0.8947     9.314  \n",
              "gbc       0.9384  0.8791  0.8815     0.529  \n",
              "et        0.9339  0.8741  0.8787     0.465  \n",
              "lr        0.9336  0.8715  0.8748     0.498  \n",
              "rf        0.9312  0.8665  0.8700     0.560  \n",
              "ada       0.9322  0.8665  0.8685     0.197  \n",
              "qda       0.9157  0.8360  0.8379     0.025  \n",
              "ridge     0.9067  0.8285  0.8394     0.023  \n",
              "lda       0.9067  0.8285  0.8394     0.027  \n",
              "dt        0.9106  0.8212  0.8231     0.030  \n",
              "nb        0.8202  0.6926  0.7234     0.021  \n",
              "knn       0.6404  0.2992  0.3026     0.122  \n",
              "svm       0.3646  0.0071  0.0097     0.024  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
              "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
              "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
              "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
              "               random_state=4604, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
              "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "7d82bfb9923241df8d11ac134a45ed88",
            "1fcc3dbbaf6d45139043e91695f65b38",
            "692b3f46b3bc4184a1113ff0142216f3"
          ]
        },
        "id": "nsW0zDBiy9Gm",
        "outputId": "c56208a4-1390-4e9e-8ae8-01f24d41f8dc"
      },
      "source": [
        "# Create the XGBoost Classifier for prediction \r\n",
        "xgboost=create_model('lightgbm')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9375</td>\n",
              "      <td>0.9581</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.9730</td>\n",
              "      <td>0.9351</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.8775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9981</td>\n",
              "      <td>0.9750</td>\n",
              "      <td>0.9286</td>\n",
              "      <td>0.9512</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.9011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9725</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9048</td>\n",
              "      <td>0.9268</td>\n",
              "      <td>0.8500</td>\n",
              "      <td>0.8511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.9942</td>\n",
              "      <td>0.9744</td>\n",
              "      <td>0.9048</td>\n",
              "      <td>0.9383</td>\n",
              "      <td>0.8735</td>\n",
              "      <td>0.8760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9873</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9744</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9870</td>\n",
              "      <td>0.9747</td>\n",
              "      <td>0.9750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.9821</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9487</td>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.8734</td>\n",
              "      <td>0.8737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.9808</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9474</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>0.9035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.9747</td>\n",
              "      <td>0.9859</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9744</td>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.9506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.9897</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.9730</td>\n",
              "      <td>0.9351</td>\n",
              "      <td>0.8735</td>\n",
              "      <td>0.8760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.9718</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9474</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>0.9035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9483</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9349</td>\n",
              "      <td>0.9633</td>\n",
              "      <td>0.9479</td>\n",
              "      <td>0.8967</td>\n",
              "      <td>0.8988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0181</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0319</td>\n",
              "      <td>0.0372</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9375  0.9581  0.9000  0.9730  0.9351  0.8750  0.8775\n",
              "1       0.9500  0.9981  0.9750  0.9286  0.9512  0.9000  0.9011\n",
              "2       0.9250  0.9725  0.9500  0.9048  0.9268  0.8500  0.8511\n",
              "3       0.9367  0.9942  0.9744  0.9048  0.9383  0.8735  0.8760\n",
              "4       0.9873  1.0000  0.9744  1.0000  0.9870  0.9747  0.9750\n",
              "5       0.9367  0.9821  0.9250  0.9487  0.9367  0.8734  0.8737\n",
              "6       0.9494  0.9808  0.9000  1.0000  0.9474  0.8988  0.9035\n",
              "7       0.9747  0.9859  0.9500  1.0000  0.9744  0.9494  0.9506\n",
              "8       0.9367  0.9897  0.9000  0.9730  0.9351  0.8735  0.8760\n",
              "9       0.9494  0.9718  0.9000  1.0000  0.9474  0.8988  0.9035\n",
              "Mean    0.9483  0.9833  0.9349  0.9633  0.9479  0.8967  0.8988\n",
              "SD      0.0181  0.0125  0.0319  0.0372  0.0180  0.0363  0.0360"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408,
          "referenced_widgets": [
            "0f39c80ebcb64bb6ab6782cb467dad2c",
            "34f8b9d6e326450fb575c3beebd72475",
            "9ec615d3dde8448692f9700b8e38388d"
          ]
        },
        "id": "Oijay54nzmCW",
        "outputId": "dbc3065d-5f4b-4ad2-b37e-49bd0cfc02e5"
      },
      "source": [
        "tuned_xgboost=tune_model(xgboost,n_iter=200)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9644</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9737</td>\n",
              "      <td>0.9487</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.9011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9125</td>\n",
              "      <td>0.9806</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9024</td>\n",
              "      <td>0.9136</td>\n",
              "      <td>0.8250</td>\n",
              "      <td>0.8253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9620</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>0.9744</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.9620</td>\n",
              "      <td>0.9241</td>\n",
              "      <td>0.9244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9747</td>\n",
              "      <td>0.9994</td>\n",
              "      <td>0.9487</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9737</td>\n",
              "      <td>0.9493</td>\n",
              "      <td>0.9505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.9367</td>\n",
              "      <td>0.9853</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.9730</td>\n",
              "      <td>0.9351</td>\n",
              "      <td>0.8735</td>\n",
              "      <td>0.8760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.9859</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9474</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>0.9035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.9620</td>\n",
              "      <td>0.9923</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9610</td>\n",
              "      <td>0.9241</td>\n",
              "      <td>0.9268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9494</td>\n",
              "      <td>0.9833</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>0.9737</td>\n",
              "      <td>0.9487</td>\n",
              "      <td>0.8988</td>\n",
              "      <td>0.8999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9620</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>0.9250</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9610</td>\n",
              "      <td>0.9241</td>\n",
              "      <td>0.9268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9559</td>\n",
              "      <td>0.9854</td>\n",
              "      <td>0.9348</td>\n",
              "      <td>0.9773</td>\n",
              "      <td>0.9551</td>\n",
              "      <td>0.9118</td>\n",
              "      <td>0.9134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0219</td>\n",
              "      <td>0.0120</td>\n",
              "      <td>0.0299</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>0.0218</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9500  0.9644  0.9250  0.9737  0.9487  0.9000  0.9011\n",
              "1       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
              "2       0.9125  0.9806  0.9250  0.9024  0.9136  0.8250  0.8253\n",
              "3       0.9620  0.9968  0.9744  0.9500  0.9620  0.9241  0.9244\n",
              "4       0.9747  0.9994  0.9487  1.0000  0.9737  0.9493  0.9505\n",
              "5       0.9367  0.9853  0.9000  0.9730  0.9351  0.8735  0.8760\n",
              "6       0.9494  0.9859  0.9000  1.0000  0.9474  0.8988  0.9035\n",
              "7       0.9620  0.9923  0.9250  1.0000  0.9610  0.9241  0.9268\n",
              "8       0.9494  0.9833  0.9250  0.9737  0.9487  0.8988  0.8999\n",
              "9       0.9620  0.9660  0.9250  1.0000  0.9610  0.9241  0.9268\n",
              "Mean    0.9559  0.9854  0.9348  0.9773  0.9551  0.9118  0.9134\n",
              "SD      0.0219  0.0120  0.0299  0.0300  0.0218  0.0437  0.0435"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}